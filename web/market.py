"""
å¸‚å ´æ•¸æ“šåŠ è¼‰å™¨

è² è²¬è¼‰å…¥å¸‚å ´æŒ‡æ•¸ã€åŒ¯ç‡ç­‰æ•¸æ“š
"""
import pickle
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Optional

import pandas as pd
import yfinance as yf

from core.config import CACHE_DIR, MARKET_CACHE_FILE


class MarketDataLoader:
    """
    å¸‚å ´æ•¸æ“šåŠ è¼‰å™¨
    
    è¨­è¨ˆåŸå‰‡ï¼š
    - åˆå§‹åŒ–æ™‚è¼‰å…¥æ‰€æœ‰å¸‚å ´è³‡æ–™ï¼ˆmax ç¯„åœï¼‰
    - ä¼ºæœå™¨é‹è¡ŒæœŸé–“åªå¾å¿«å–è®€å–ï¼Œä¸å†å¾ yfinance æŠ“å–
    - ä¸åŒ period å¾å·²è¼‰å…¥çš„è³‡æ–™ä¸­åˆ‡ç‰‡
    """
    
    # é è¼‰çš„å¸‚å ´æŒ‡æ•¸ï¼ˆåŒ…å«åŒ¯ç‡ TWD=Xï¼‰
    MARKET_SYMBOLS = ['^IXIC', '^TWII', 'GC=F', 'BTC-USD', 'TLT', '^GSPC', 'TWD=X']
    
    def __init__(self):
        self.cache: Dict[str, pd.DataFrame] = {}
        self.cache_time: Dict[str, datetime] = {}
        self.exchange_rate: float = 32.0
        self.initialized: bool = False
        
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
        self._load_cache_from_disk()
    
    def _load_cache_from_disk(self) -> bool:
        """å¾ç£ç¢Ÿè¼‰å…¥å¿«å–"""
        if not MARKET_CACHE_FILE.exists():
            print(f"âš ï¸ å¸‚å ´å¿«å–æª”æ¡ˆä¸å­˜åœ¨: {MARKET_CACHE_FILE}")
            return False
        
        try:
            print(f"ğŸ“¥ æ­£åœ¨è®€å–å¸‚å ´å¿«å–æª”æ¡ˆ...")
            with open(MARKET_CACHE_FILE, 'rb') as f:
                saved = pickle.load(f)
                self.cache = saved.get('data', {})
                self.cache_time = saved.get('time', {})
                self.exchange_rate = saved.get('exchange_rate', 32.0)
                print(f"âœ… è¼‰å…¥å¸‚å ´è³‡æ–™å¿«å–æˆåŠŸ")
                print(f"   - å…± {len(self.cache)} å€‹ symbol")
                for sym, df in self.cache.items():
                    if isinstance(df, pd.DataFrame):
                        print(f"   - {sym}: {len(df)} ç­†è³‡æ–™")
                return True
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥å¸‚å ´å¿«å–å¤±æ•—: {e}")
            print(f"   æç¤º: å¯èƒ½æ˜¯ pandas ç‰ˆæœ¬ä¸ç›¸å®¹ï¼Œéœ€é‡æ–°ç”¢ç”Ÿ cache")
            return False
    
    def _save_cache_to_disk(self):
        """å°‡å¿«å–å­˜å…¥ç£ç¢Ÿ"""
        try:
            with open(MARKET_CACHE_FILE, 'wb') as f:
                pickle.dump({
                    'data': self.cache,
                    'time': self.cache_time,
                    'exchange_rate': self.exchange_rate
                }, f)
            print(f"   âœ… å·²å„²å­˜è‡³ {MARKET_CACHE_FILE}")
        except Exception as e:
            print(f"   âŒ å„²å­˜å¸‚å ´å¿«å–å¤±æ•—: {e}")
    
    def _has_cache(self, symbol: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰è©² symbol çš„å¿«å–"""
        return symbol in self.cache and not self.cache[symbol].empty
    
    def _filter_by_period(self, df: pd.DataFrame, period: str) -> pd.DataFrame:
        """æ ¹æ“š period éæ¿¾ DataFrame"""
        if df.empty:
            return df
        
        period_days = {
            '1mo': 30, '3mo': 90, '6mo': 180,
            '1y': 365, '2y': 730, '5y': 1825, '6y': 2190
        }
        
        if period in period_days:
            cutoff = datetime.now() - timedelta(days=period_days[period])
            return df[df.index >= cutoff].copy()
        
        return df.copy()
    
    def preload_all(self, aligned_data: dict = None, max_staleness_days: int = 1):
        """
        é è¼‰æ‰€æœ‰å¸‚å ´è³‡æ–™ï¼ˆæ™ºæ…§å¿«å–ç­–ç•¥ï¼‰
        
        Args:
            aligned_data: å·²å°é½Šçš„è‚¡ç¥¨è³‡æ–™
            max_staleness_days: å…è¨±çš„æœ€å¤§éæœŸå¤©æ•¸
        """
        print(f"\nğŸ”„ é–‹å§‹é è¼‰å¸‚å ´è³‡æ–™...")
        
        now = datetime.now()
        today = now.date()
        rate_limited = False
        
        for symbol in self.MARKET_SYMBOLS:
            print(f"\n   ğŸ“Š è™•ç† {symbol}...")
            
            # æª¢æŸ¥å¿«å–
            if symbol in self.cache and isinstance(self.cache[symbol], pd.DataFrame):
                cached_df = self.cache[symbol]
                if not cached_df.empty:
                    cache_latest_date = cached_df.index[-1].date()
                    days_diff = (today - cache_latest_date).days
                    
                    if days_diff <= max_staleness_days:
                        print(f"      âœ… å¿«å–æœ‰æ•ˆ")
                        continue
            
            if rate_limited:
                print(f"      âš ï¸ å·²è¢«é™é€Ÿï¼Œè·³é")
                continue
            
            # å¾ aligned_data è®€å–
            if aligned_data and symbol in aligned_data:
                df = aligned_data[symbol].copy()
                if not df.empty:
                    print(f"      âœ… å¾ aligned_data è¼‰å…¥ ({len(df)} ç­†)")
                    self.cache[symbol] = df
                    self.cache_time[symbol] = now
                    continue
            
            # å¾ yfinance æŠ“å–
            try:
                print(f"      ğŸ“¥ å¾ yfinance æŠ“å–...")
                ticker = yf.Ticker(symbol)
                df = ticker.history(period="max", interval="1d")
                
                if df.empty:
                    print(f"      âŒ ç„¡è³‡æ–™")
                    continue
                
                df = df.tz_localize(None)
                df = df.sort_index()
                print(f"      âœ… æˆåŠŸ ({len(df)} ç­†)")
                self.cache[symbol] = df
                self.cache_time[symbol] = now
                
            except Exception as e:
                print(f"      âŒ å¤±æ•—: {e}")
                if "Rate limited" in str(e) or "Too Many Requests" in str(e):
                    rate_limited = True
        
        # è¨­å®šåŒ¯ç‡
        if self._has_cache('TWD=X'):
            self.exchange_rate = round(self.cache['TWD=X']['Close'].iloc[-1], 2)
            print(f"\n   ğŸ’± åŒ¯ç‡: {self.exchange_rate}")
        
        self._save_cache_to_disk()
        self.initialized = True
        print(f"âœ… å¸‚å ´è³‡æ–™é è¼‰å®Œæˆ\n")
    
    def get_index_data(self, symbol: str, period: str = "2y", 
                       aligned_data: dict = None) -> pd.DataFrame:
        """ç²å–æŒ‡æ•¸æ­·å²æ•¸æ“š"""
        if self._has_cache(symbol):
            return self._filter_by_period(self.cache[symbol], period)
        
        if aligned_data and symbol in aligned_data:
            df = aligned_data[symbol].copy()
            return self._filter_by_period(df, period)
        
        if self.initialized:
            return pd.DataFrame()
        
        # åˆå§‹åŒ–æœŸé–“å…è¨±æŠ“å–
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(period="max", interval="1d")
            df = df.tz_localize(None).sort_index()
            
            if not df.empty:
                self.cache[symbol] = df
                self.cache_time[symbol] = datetime.now()
                self._save_cache_to_disk()
            
            return self._filter_by_period(df, period)
        except Exception as e:
            print(f"Error fetching {symbol}: {e}")
            return pd.DataFrame()
    
    def get_weighted_kline(self, symbol: str, period: str = "2y", 
                          aligned_data: dict = None) -> list:
        """ç²å– K ç·šæ•¸æ“šï¼ˆä¾›å‰ç«¯åœ–è¡¨ï¼‰"""
        df = self.get_index_data(symbol, period, aligned_data)
        
        if df.empty:
            return []
        
        kline_data = []
        for idx, row in df.iterrows():
            if pd.isna(row['Open']) or pd.isna(row['Close']):
                continue
            
            kline_data.append({
                'time': idx.strftime('%Y-%m-%d'),
                'open': round(row['Open'], 2),
                'high': round(row['High'], 2),
                'low': round(row['Low'], 2),
                'close': round(row['Close'], 2),
                'volume': int(row['Volume']) if not pd.isna(row['Volume']) else 0
            })
        
        return kline_data
    
    def get_global_weighted_index(self, period: str = "2y", 
                                  aligned_data: dict = None) -> list:
        """
        è¨ˆç®—åœ‹éš›åŠ æ¬ŠæŒ‡æ•¸ (NASDAQ èˆ‡å°è‚¡ 1:1 æ¬Šé‡)
        
        æ­£ç¢ºåšæ³•ï¼šä»¥å°å¹£è¨ˆåƒ¹
        - å…ˆæŠŠ NASDAQ çš„ USD åƒ¹æ ¼ç”¨ç•¶å¤©åŒ¯ç‡æ›æˆ TWD
        - å†è·Ÿ TWII (æœ¬èº«å·²æ˜¯ TWD) åš 1:1 åŠ æ¬Šå¹³å‡
        """
        nasdaq_df = self.get_index_data('^IXIC', period, aligned_data)
        twii_df = self.get_index_data('^TWII', period, aligned_data)
        
        if nasdaq_df.empty or twii_df.empty:
            return []
        
        # ç²å–åŒ¯ç‡è³‡æ–™
        fx_history = self.get_exchange_rate_history('6y')
        
        common_dates = nasdaq_df.index.intersection(twii_df.index)
        if len(common_dates) == 0:
            return []
        
        kline_data = []
        first_nq_twd = None
        first_tw = None
        
        for date in sorted(common_dates):
            date_str = date.strftime('%Y-%m-%d')
            nq = nasdaq_df.loc[date]
            tw = twii_df.loc[date]
            
            # ç²å–ç•¶å¤©åŒ¯ç‡ï¼ˆæ‰¾æœ€è¿‘æœ‰æ•ˆåŒ¯ç‡ï¼‰
            fx_rate = fx_history.get(date_str)
            if fx_rate is None:
                # æ‰¾æœ€è¿‘çš„åŒ¯ç‡
                for d in sorted(fx_history.keys(), reverse=True):
                    if d <= date_str:
                        fx_rate = fx_history[d]
                        break
            if fx_rate is None:
                fx_rate = self.exchange_rate  # é è¨­åŒ¯ç‡
            
            # å°‡ NASDAQ æ›æˆå°å¹£
            nq_open_twd = nq['Open'] * fx_rate
            nq_high_twd = nq['High'] * fx_rate
            nq_low_twd = nq['Low'] * fx_rate
            nq_close_twd = nq['Close'] * fx_rate
            
            # è¨˜éŒ„ç¬¬ä¸€å¤©çš„åƒ¹æ ¼ï¼ˆç”¨æ–¼æ¨™æº–åŒ–ï¼‰
            if first_nq_twd is None:
                first_nq_twd = nq_close_twd
                first_tw = tw['Close']
            
            # æ¨™æº–åŒ–å¾ŒåŠ æ¬Šï¼ˆè®“å…©è€…å¾ç›¸åŒèµ·é» 100 é–‹å§‹ï¼‰
            nq_normalized = (nq_close_twd / first_nq_twd) * 100
            tw_normalized = (tw['Close'] / first_tw) * 100
            
            # 1:1 åŠ æ¬Šå¹³å‡
            weighted_close = (nq_normalized + tw_normalized) / 2
            
            # open/high/low ä¹Ÿåšé¡ä¼¼è™•ç†ï¼ˆç”¨æ”¶ç›¤åƒ¹æ¯”ä¾‹è¿‘ä¼¼ï¼‰
            if nq_close_twd > 0 and tw['Close'] > 0:
                nq_open_norm = (nq_open_twd / first_nq_twd) * 100
                nq_high_norm = (nq_high_twd / first_nq_twd) * 100
                nq_low_norm = (nq_low_twd / first_nq_twd) * 100
                tw_open_norm = (tw['Open'] / first_tw) * 100
                tw_high_norm = (tw['High'] / first_tw) * 100
                tw_low_norm = (tw['Low'] / first_tw) * 100
                
                weighted_open = (nq_open_norm + tw_open_norm) / 2
                weighted_high = (nq_high_norm + tw_high_norm) / 2
                weighted_low = (nq_low_norm + tw_low_norm) / 2
            else:
                weighted_open = weighted_close
                weighted_high = weighted_close
                weighted_low = weighted_close
            
            actual_high = max(weighted_open, weighted_high, weighted_low, weighted_close)
            actual_low = min(weighted_open, weighted_high, weighted_low, weighted_close)
            
            kline_data.append({
                'time': date_str,
                'open': round(weighted_open, 2),
                'high': round(actual_high, 2),
                'low': round(actual_low, 2),
                'close': round(weighted_close, 2),
                'volume': int(nq['Volume'] + tw['Volume'])
            })
        
        return kline_data
    
    def get_all_market_data(self, period: str = "2y", aligned_data: dict = None) -> dict:
        """ç²å–æ‰€æœ‰å¸‚å ´æ•¸æ“š"""
        return {
            'global': self.get_global_weighted_index(period, aligned_data),
            'nasdaq': self.get_weighted_kline('^IXIC', period, aligned_data),
            'twii': self.get_weighted_kline('^TWII', period, aligned_data),
            'gold': self.get_weighted_kline('GC=F', period, aligned_data),
            'btc': self.get_weighted_kline('BTC-USD', period, aligned_data),
            'bonds': self.get_weighted_kline('TLT', period, aligned_data)
        }
    
    def get_exchange_rate(self) -> float:
        """ç²å–ç¾å…ƒå…Œå°å¹£åŒ¯ç‡"""
        return self.exchange_rate
    
    def get_exchange_rate_history(self, period: str = "6y") -> dict:
        """ç²å–æ­·å²åŒ¯ç‡æ•¸æ“š"""
        if not self._has_cache('TWD=X'):
            return {}
        
        df = self._filter_by_period(self.cache['TWD=X'], period)
        if df.empty:
            return {}
        
        return {
            date.strftime('%Y-%m-%d'): round(row['Close'], 4)
            for date, row in df.iterrows()
        }
