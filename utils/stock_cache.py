"""
è‚¡ç¥¨æ•¸æ“šå¿«å–æ¨¡çµ„ - é è¼‰å…¥ TradingView æ¸…å–®ä¸­çš„æ‰€æœ‰è‚¡ç¥¨æ­·å²è³‡æ–™

================================================================================
                              ç³»çµ±è¨­è¨ˆè¦ç¯„ï¼ˆé‡è¦ï¼‰
================================================================================

ã€åˆå§‹åŒ–è³‡æ–™æŠ“å–åŸå‰‡ã€‘âš ï¸ æ¥µé‡è¦ âš ï¸
    âœ… æ‰€æœ‰è‚¡ç¥¨è³‡æ–™å¿…é ˆåœ¨åˆå§‹åŒ–æ™‚ä¸€æ¬¡æŠ“å–å®Œæˆï¼š
       - å¸‚å ´æŒ‡æ•¸ï¼ˆ^IXIC, ^TWII, GC=F, BTC-USD, TLTï¼‰
       - æ‰€æœ‰ TradingView watchlist ä¸­çš„å€‹è‚¡
       - çµ±ä¸€æŠ“å– 6 å¹´è³‡æ–™ï¼ˆæŒ‡æ¨™è¨ˆç®—éœ€è¦ 1 å¹´ï¼Œå¯¦éš›å¯ç”¨ 5 å¹´ï¼‰
    
    âœ… æŠ“å–å¾Œç«‹å³å„²å­˜åˆ° pickle å¿«å–ï¼š
       - é¿å…é‡è¤‡å‘¼å« yfinance API
       - æ¸›å°‘ API ç”¨é‡å’Œè¢«å°é–é¢¨éšª
    
    âŒ ç¦æ­¢åœ¨éœ€è¦æ™‚æ‰å‹•æ…‹æŠ“å–ï¼š
       - ä¸è¦åœ¨ API è«‹æ±‚æ™‚æ‰å»æŠ“å€‹è‚¡è³‡æ–™
       - ä¸è¦åœ¨è¨ˆç®—æŒ‡æ¨™æ™‚æ‰å»æŠ“æ­·å²è³‡æ–™
       - é€™æ¨£åšæœƒå°è‡´ API ç”¨é‡çˆ†ç‚¸ï¼
    
    ğŸ“… è³‡æ–™æœŸé–“èªªæ˜ï¼š
       - æŠ“å–æœŸé–“ï¼š6 å¹´ï¼ˆperiod="6y"ï¼‰
       - æŒ‡æ¨™è¨ˆç®—æ¶ˆè€—ï¼šç´„ 252 å¤©ï¼ˆ1 å¹´æ»¾å‹•çª—å£ï¼‰
       - å¯¦éš›å¯ç”¨ï¼šç´„ 5 å¹´å›æ¸¬è³‡æ–™

ã€å¿«å–å„²å­˜åŸå‰‡ã€‘
    âœ… å¿«å–åªå­˜ã€ŒåŸå§‹è³‡æ–™ã€ï¼š
       - OHLCVï¼ˆOpen, High, Low, Close, Volumeï¼‰
       - watchlistï¼ˆç”¢æ¥­åˆ†é¡çµæ§‹ï¼‰
       - stock_infoï¼ˆè‚¡ç¥¨åŸºæœ¬è³‡è¨Šï¼šåœ‹å®¶ã€ç”¢æ¥­ã€äº¤æ˜“æ‰€ï¼‰
       - last_updateï¼ˆæœ€å¾Œæ›´æ–°æ™‚é–“ï¼‰
    
    âŒ å¿«å–ç¦æ­¢å­˜ã€Œè¡ç”ŸæŒ‡æ¨™ã€ï¼š
       - Sharpe Ratioï¼ˆéœ€å‹•æ…‹è¨ˆç®—ï¼‰
       - Sharpe Daily Changeï¼ˆéœ€å‹•æ…‹è¨ˆç®—ï¼‰
       - Returnsï¼ˆéœ€å‹•æ…‹è¨ˆç®—ï¼‰
       - ä»»ä½•åŸºæ–¼åŸå§‹è³‡æ–™è¨ˆç®—å‡ºä¾†çš„æŒ‡æ¨™

ã€è¡ç”ŸæŒ‡æ¨™è¨ˆç®—åŸå‰‡ã€‘
    - æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™å¿…é ˆåœ¨ _calculate_all_indicators() ä¸­è¨ˆç®—
    - æ¯æ¬¡è¼‰å…¥å¿«å–å¾Œéƒ½æœƒé‡æ–°è¨ˆç®—è¡ç”ŸæŒ‡æ¨™
    - é€™æ¨£è¨­è¨ˆçš„å¥½è™•ï¼š
      1. å¿«å–æª”æ¡ˆæ›´å°
      2. ä¿®æ”¹è¨ˆç®—é‚è¼¯ä¸éœ€é‡æ–°ä¸‹è¼‰è³‡æ–™
      3. æ–°å¢æŒ‡æ¨™åªéœ€ä¿®æ”¹è¨ˆç®—å‡½æ•¸
      4. è³‡æ–™å„²å­˜èˆ‡è¨ˆç®—é‚è¼¯å®Œå…¨åˆ†é›¢

ã€ä¿®æ”¹æ³¨æ„äº‹é …ã€‘
    - æ–°å¢æŒ‡æ¨™æ™‚ï¼Œåœ¨ _calculate_all_indicators() ä¸­æ·»åŠ è¨ˆç®—é‚è¼¯
    - ä¸è¦åœ¨ _save_to_cache() ä¸­åŠ å…¥ä»»ä½•è¡ç”ŸæŒ‡æ¨™
    - ä¸è¦åœ¨ _fetch_stock_history() ä¸­è¨ˆç®—ä»»ä½•æŒ‡æ¨™
    - raw_data ä¸­çš„ DataFrame åªèƒ½æœ‰ OHLCV äº”å€‹æ¬„ä½

================================================================================
                              è¨ˆç®—å…¬å¼èªªæ˜
================================================================================

ã€Sharpe Ratioï¼ˆå¤æ™®æ¯”ç‡ï¼‰ã€‘
    ç”¨é€”ï¼šè¡¡é‡é¢¨éšªèª¿æ•´å¾Œå ±é…¬ï¼Œå€¼è¶Šé«˜ä»£è¡¨å ±é…¬/é¢¨éšªæ¯”è¶Šå¥½
    
    å…¬å¼ï¼š
        Sharpe = (æ»¾å‹•å¹³å‡è¶…é¡å ±é…¬ / æ»¾å‹•æ¨™æº–å·®) Ã— âˆš252
    
    å…¶ä¸­ï¼š
        - è¶…é¡å ±é…¬ = æ—¥å ±é…¬ç‡ - æ—¥ç„¡é¢¨éšªåˆ©ç‡
        - æ—¥ç„¡é¢¨éšªåˆ©ç‡ = å¹´ç„¡é¢¨éšªåˆ©ç‡(4%) / 252
        - æ»¾å‹•è¦–çª— = 252 å¤©ï¼ˆç´„ä¸€å¹´äº¤æ˜“æ—¥ï¼‰
    
    è§£è®€ï¼š
        - Sharpe > 1ï¼šå„ªè‰¯
        - Sharpe > 2ï¼šéå¸¸å„ªç§€
        - Sharpe < 0ï¼šè™§æ

ã€Sharpe Daily Changeï¼ˆå¤æ™®å–®æ—¥è®ŠåŒ–ï¼‰ã€‘
    ç”¨é€”ï¼šæ‰¾å‡ºã€Œç•¶ç´…ç‚¸å­é›ã€- ç•¶å‰å¸‚å ´ä¸­ Sharpe å¢é•·æœ€å¿«çš„è‚¡ç¥¨
    
    å…¬å¼ï¼š
        Daily Change = Sharpe(today) - Sharpe(yesterday)
    
    ç‰¹é»ï¼š
        - ä½¿ç”¨ç°¡å–®å·®å€¼ï¼Œä¸æ˜¯ç·šæ€§å›æ­¸æ–œç‡
        - ä¸éæ¿¾ Sharpe > 0ï¼Œå› ç‚ºç›®æ¨™æ˜¯æ‰¾å¢é•·æœ€å¿«çš„è‚¡ç¥¨
        - å³ä½¿ Sharpe ç‚ºè² ä½†æ­£åœ¨å¿«é€Ÿå›å‡ï¼Œä¹Ÿæœƒè¢«ç´å…¥
    
    âš ï¸ æ³¨æ„ï¼šé€™èˆ‡ src/stock.py ä¸­ç”¨æ–¼ MA è¨ˆç®—çš„ Sharpe_Slopeï¼ˆ365å¤©æ–œç‡ï¼‰ä¸åŒï¼
        - å‰ç«¯ã€Œå¢é•·ç‡ Top 15ã€ï¼šä½¿ç”¨æ­¤è™•çš„ Daily Change
        - å¾Œç«¯è²·é€²å»ºè­°ï¼šä½¿ç”¨ src/stock.py çš„ 365 å¤©ç·šæ€§å›æ­¸æ–œç‡

================================================================================
"""
import pickle
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from pathlib import Path


# å¿«å–ç›®éŒ„
CACHE_DIR = Path(__file__).parent.parent / "cache"
CACHE_FILE = CACHE_DIR / "stock_data.pkl"


class StockDataCache:
    """è‚¡ç¥¨æ•¸æ“šå¿«å–å™¨"""
    
    # TradingView è¨­å®š
    WATCHLIST_ID = "118349730"
    SESSION_ID = "b379eetq1pojcel6olyymmpo1rd41nng"
    
    # è¨ˆç®—åƒæ•¸
    SHARPE_WINDOW = 252   # Sharpe è¨ˆç®—è¦–çª—
    RISK_FREE_RATE = 0.04
    
    def __init__(self, auto_load: bool = True):
        # ====================================================================
        # åŸå§‹è³‡æ–™ï¼ˆæœƒè¢«å¿«å–åˆ° pickleï¼‰
        # æ³¨æ„ï¼šåªæœ‰é€™äº›è³‡æ–™æœƒè¢«å­˜å…¥å¿«å–ï¼
        # ====================================================================
        self.raw_data = {}    # {ticker: DataFrame with OHLCV only}
        self.watchlist = {}   # {industry: {provider: [codes]}}
        self.stock_info = {}  # {ticker: {country, industry, provider}}
        self.last_update = None
        
        # ====================================================================
        # è¡ç”Ÿè³‡æ–™ï¼ˆå‹•æ…‹è¨ˆç®—ï¼Œç¦æ­¢å¿«å–ï¼ï¼‰
        # é€™äº›è³‡æ–™åœ¨æ¯æ¬¡è¼‰å…¥å¾Œç”± _calculate_all_indicators() è¨ˆç®—
        # ====================================================================
        self.sharpe_matrix = None   # ç”± raw_data è¨ˆç®—å¾—å‡º
        self.slope_matrix = None    # Sharpe å–®æ—¥è®ŠåŒ–ï¼ˆtoday - yesterdayï¼‰
        self.initialized = False
        
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
        
        if auto_load:
            self.load_or_fetch()
    
    def load_or_fetch(self, force_refresh: bool = False):
        """è¼‰å…¥å¿«å–æˆ–é‡æ–°æŠ“å–è³‡æ–™"""
        if not force_refresh and self._load_from_cache():
            print(f"âœ… å¾å¿«å–è¼‰å…¥åŸå§‹è³‡æ–™ (æœ€å¾Œæ›´æ–°: {self.last_update})")
        else:
            print("ğŸ“¥ é–‹å§‹æŠ“å–è‚¡ç¥¨è³‡æ–™...")
            self._fetch_all_data()
            self._save_to_cache()
            print(f"âœ… è‚¡ç¥¨è³‡æ–™æŠ“å–å®Œæˆ ({len(self.raw_data)} æª”è‚¡ç¥¨)")
        
        # è¼‰å…¥å¾Œè¨ˆç®—è¡ç”ŸæŒ‡æ¨™
        print("ğŸ“Š è¨ˆç®—è¡ç”ŸæŒ‡æ¨™...")
        self._calculate_all_indicators()
        self.initialized = True
        print(f"âœ… æŒ‡æ¨™è¨ˆç®—å®Œæˆ")
    
    # ===== å¿«å–ç®¡ç† =====
    
    def _load_from_cache(self) -> bool:
        """å¾å¿«å–è¼‰å…¥åŸå§‹è³‡æ–™"""
        if not CACHE_FILE.exists():
            return False
        
        try:
            with open(CACHE_FILE, 'rb') as f:
                cache = pickle.load(f)
            
            cache_time = cache.get('last_update')
            if cache_time:
                cache_age = datetime.now() - cache_time
                if cache_age > timedelta(days=1):
                    print("âš ï¸ å¿«å–å·²éæœŸï¼Œå°‡é‡æ–°æŠ“å–")
                    return False
            
            self.raw_data = cache.get('raw_data', {})
            self.watchlist = cache.get('watchlist', {})
            self.stock_info = cache.get('stock_info', {})
            self.last_update = cache.get('last_update')
            
            return len(self.raw_data) > 0
            
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥å¿«å–å¤±æ•—: {e}")
            return False
    
    def _save_to_cache(self):
        """
        å„²å­˜åŸå§‹è³‡æ–™åˆ°å¿«å–
        
        âš ï¸ é‡è¦ï¼šç¦æ­¢åœ¨æ­¤åŠ å…¥ä»»ä½•è¡ç”ŸæŒ‡æ¨™ï¼
        - âŒ ä¸è¦åŠ å…¥ sharpe_matrix
        - âŒ ä¸è¦åŠ å…¥ slope_matrix
        - âŒ ä¸è¦åŠ å…¥ä»»ä½•è¨ˆç®—å‡ºä¾†çš„è³‡æ–™
        """
        try:
            # åªå­˜åŸå§‹è³‡æ–™ï¼Œä¸å­˜è¡ç”ŸæŒ‡æ¨™
            cache = {
                'raw_data': self.raw_data,      # åªæœ‰ OHLCV
                'watchlist': self.watchlist,    # ç”¢æ¥­åˆ†é¡
                'stock_info': self.stock_info,  # è‚¡ç¥¨åŸºæœ¬è³‡è¨Š
                'last_update': self.last_update # æ›´æ–°æ™‚é–“
                # âŒ ç¦æ­¢åŠ å…¥ sharpe_matrix, slope_matrix ç­‰è¡ç”Ÿè³‡æ–™
            }
            with open(CACHE_FILE, 'wb') as f:
                pickle.dump(cache, f)
            print(f"ğŸ’¾ å·²å„²å­˜å¿«å–è‡³ {CACHE_FILE}")
        except Exception as e:
            print(f"âš ï¸ å„²å­˜å¿«å–å¤±æ•—: {e}")
    
    # ===== è³‡æ–™æŠ“å– =====
    
    def _fetch_watchlist(self) -> dict:
        """å¾ TradingView å–å¾—æŠ•è³‡çµ„åˆæ¸…å–®"""
        import requests
        
        url = f'https://in.tradingview.com/api/v1/symbols_list/custom/{self.WATCHLIST_ID}'
        headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'cookie': f'sessionid={self.SESSION_ID}',
            'x-requested-with': 'XMLHttpRequest',
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            symbols = response.json()["symbols"]
        except Exception as e:
            print(f"âš ï¸ TradingView ç„¡å›æ‡‰: {e}")
            return {}
        
        result = {}
        current_key = None
        
        for item in symbols:
            if "###" in item:
                current_key = item.strip("###\u2064")
                result[current_key] = {}
            elif current_key:
                provider, code = item.split(":", 1)
                if provider not in result[current_key]:
                    result[current_key][provider] = []
                
                # è½‰æ›ç‚º yfinance æ ¼å¼
                if provider in ['NASDAQ', 'NYSE']:
                    yf_code = code
                    country = 'US'
                elif provider == 'TWSE':
                    yf_code = f"{code}.TW"
                    country = 'TW'
                else:
                    continue
                
                result[current_key][provider].append(yf_code)
                
                self.stock_info[yf_code] = {
                    'country': country,
                    'industry': current_key,
                    'provider': provider,
                    'original_code': code
                }
        
        return result
    
    def _fetch_stock_history(self, ticker: str, period: str = "6y") -> pd.DataFrame:
        """
        ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ­·å²æ•¸æ“š
        
        âš ï¸ é‡è¦ï¼šæ­¤å‡½æ•¸åªå›å‚³åŸå§‹ OHLCV è³‡æ–™ï¼
        - âŒ ä¸è¦åœ¨é€™è£¡è¨ˆç®— Sharpe
        - âŒ ä¸è¦åœ¨é€™è£¡è¨ˆç®— Returns
        - âŒ ä¸è¦åœ¨é€™è£¡åŠ å…¥ä»»ä½•è¡ç”Ÿæ¬„ä½
        
        Returns:
            DataFrame with columns: Open, High, Low, Close, Volume (åƒ…æ­¤äº”æ¬„)
        """
        try:
            df = yf.Ticker(ticker).history(period=period, interval="1d")
            if df.empty:
                return pd.DataFrame()
            
            df = df.tz_localize(None)
            df = df.sort_index()
            # âš ï¸ åªä¿ç•™åŸå§‹æ¬„ä½ï¼Œç¦æ­¢åŠ å…¥è¡ç”Ÿæ¬„ä½ï¼
            return df[['Open', 'High', 'Low', 'Close', 'Volume']]
        except Exception as e:
            print(f"  âš ï¸ {ticker}: {e}")
            return pd.DataFrame()
    
    def _fetch_all_data(self):
        """æŠ“å–æ‰€æœ‰è‚¡ç¥¨çš„åŸå§‹è³‡æ–™ï¼ˆå«å¸‚å ´æŒ‡æ•¸ï¼‰"""
        self.watchlist = self._fetch_watchlist()
        
        if not self.watchlist:
            print("âš ï¸ ç„¡æ³•å–å¾— watchlist")
            return
        
        # å…ˆæŠ“å–å¸‚å ´æŒ‡æ•¸ï¼ˆå„ªå…ˆï¼Œç¢ºä¿ K ç·šåœ–æœ‰è³‡æ–™ï¼‰
        market_indices = [
            ('^IXIC', 'NASDAQ', 'US'),      # NASDAQ æŒ‡æ•¸
            ('^TWII', 'TWSE', 'TW'),        # å°ç£åŠ æ¬ŠæŒ‡æ•¸
            ('GC=F', 'CME', 'US'),          # é»ƒé‡‘æœŸè²¨
            ('BTC-USD', 'CRYPTO', 'US'),    # æ¯”ç‰¹å¹£
            ('TLT', 'NYSE', 'US'),          # ç¾åœ‹20å¹´æœŸå…¬å‚µ ETF
        ]
        
        # âš ï¸ é‡è¦ï¼šæ‰€æœ‰è³‡æ–™çµ±ä¸€ä½¿ç”¨ 6yï¼Œç¢ºä¿æŒ‡æ¨™è¨ˆç®—å¾Œä»æœ‰ 5 å¹´å¯ç”¨
        # ä¸è¦ä¿®æ”¹é€™å€‹å€¼ï¼å¦‚éœ€èª¿æ•´è«‹åŒæ™‚ä¿®æ”¹æª”æ¡ˆé–‹é ­çš„èªªæ˜æ–‡ä»¶
        DATA_PERIOD = "6y"
        
        print(f"ğŸ“ˆ æŠ“å–å¸‚å ´æŒ‡æ•¸ï¼ˆ{DATA_PERIOD}ï¼‰...")
        for ticker, provider, country in market_indices:
            print(f"  æŠ“å– {ticker}...", end=" ")
            df = self._fetch_stock_history(ticker, period=DATA_PERIOD)
            
            if df.empty:
                print("âŒ ç„¡è³‡æ–™")
                continue
            
            self.raw_data[ticker] = df
            self.stock_info[ticker] = {
                'country': country,
                'industry': 'Market Index',
                'provider': provider,
                'original_code': ticker
            }
            print(f"âœ… {len(df)} ç­†")
        
        all_tickers = list(self.stock_info.keys())
        # éæ¿¾æ‰å·²ç¶“æŠ“å–çš„å¸‚å ´æŒ‡æ•¸
        stock_tickers = [t for t in all_tickers if t not in [m[0] for m in market_indices]]
        print(f"ğŸ“Š å…± {len(stock_tickers)} æª”è‚¡ç¥¨å¾…æŠ“å–")
        
        for i, ticker in enumerate(stock_tickers):
            print(f"  [{i+1}/{len(stock_tickers)}] æŠ“å– {ticker}...", end=" ")
            
            # âš ï¸ ä½¿ç”¨çµ±ä¸€çš„ DATA_PERIODï¼Œä¸è¦ç¡¬ç·¨ç¢¼ï¼
            df = self._fetch_stock_history(ticker, period=DATA_PERIOD)
            
            if df.empty:
                print("âŒ ç„¡è³‡æ–™")
                continue
            
            self.raw_data[ticker] = df
            print(f"âœ… {len(df)} ç­†")
        
        self.last_update = datetime.now()
    
    # =========================================================================
    # è¡ç”ŸæŒ‡æ¨™è¨ˆç®—å€
    # =========================================================================
    # æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™çš„è¨ˆç®—é‚è¼¯éƒ½æ”¾åœ¨é€™è£¡
    # æ–°å¢æŒ‡æ¨™æ™‚ï¼š
    #   1. æ–°å¢è¨ˆç®—å‡½æ•¸ï¼ˆå¦‚ _calculate_xxxï¼‰
    #   2. åœ¨ _calculate_all_indicators() ä¸­èª¿ç”¨
    #   3. åœ¨ class ä¸­æ–°å¢å°æ‡‰çš„ matrix å±¬æ€§ï¼ˆè¨­ç‚º Noneï¼‰
    # =========================================================================
    
    def _calculate_sharpe(self, close_series: pd.Series) -> pd.Series:
        """è¨ˆç®—æ»¾å‹• Sharpe æ¯”ç‡"""
        if close_series.empty:
            return pd.Series(dtype=float)
        
        returns = close_series.pct_change()
        daily_rf = self.RISK_FREE_RATE / self.SHARPE_WINDOW
        excess_returns = returns - daily_rf
        
        rolling_mean = excess_returns.rolling(self.SHARPE_WINDOW).mean()
        rolling_std = excess_returns.rolling(self.SHARPE_WINDOW).std()
        
        sharpe = rolling_mean / rolling_std * np.sqrt(self.SHARPE_WINDOW)
        return sharpe
    
    def _calculate_daily_change(self, series: pd.Series) -> pd.Series:
        """
        è¨ˆç®—å–®æ—¥è®ŠåŒ–é‡ï¼ˆtoday - yesterdayï¼‰
        
        ç”¨æ–¼å‰ç«¯ã€Œå¢é•·ç‡ Top 15ã€é¡¯ç¤ºï¼Œæ‰¾å‡ºç•¶ç´…ç‚¸å­é›
        ä¸éæ¿¾ Sharpe > 0ï¼Œå› ç‚ºç›®æ¨™æ˜¯æ‰¾å‡ºå¢é•·æœ€å¿«çš„è‚¡ç¥¨
        """
        if series.empty:
            return pd.Series(dtype=float)
        
        # ç°¡å–®çš„æ—¥å·®å€¼ï¼šä»Šå¤© - æ˜¨å¤©
        return series.diff()
    
    def _calculate_all_indicators(self):
        """
        è¨ˆç®—æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™ï¼ˆæ¯æ¬¡è¼‰å…¥å¿«å–å¾ŒåŸ·è¡Œï¼‰
        
        é€™æ˜¯è¡ç”ŸæŒ‡æ¨™çš„å”¯ä¸€è¨ˆç®—å…¥å£é»ï¼
        æ–°å¢æŒ‡æ¨™æ™‚ï¼Œåœ¨é€™è£¡æ·»åŠ è¨ˆç®—é‚è¼¯ã€‚
        
        ç›®å‰è¨ˆç®—çš„æŒ‡æ¨™ï¼š
        - sharpe_matrix: æ»¾å‹• Sharpe Ratioï¼ˆ252å¤©è¦–çª—ï¼‰
        - slope_matrix: Sharpe å–®æ—¥è®ŠåŒ–ï¼ˆtoday - yesterdayï¼‰ï¼Œç”¨æ–¼æ‰¾ç•¶ç´…ç‚¸å­é›
        """
        sharpe_data = {}
        slope_data = {}
        
        for ticker, df in self.raw_data.items():
            if 'Close' not in df.columns:
                continue
            
            # è¨ˆç®— Sharpe
            sharpe = self._calculate_sharpe(df['Close'])
            sharpe_data[ticker] = sharpe
            
            # è¨ˆç®— Sharpe å–®æ—¥è®ŠåŒ–ï¼ˆä¸æ˜¯ 365 å¤©æ–œç‡ï¼ï¼‰
            daily_change = self._calculate_daily_change(sharpe)
            slope_data[ticker] = daily_change
        
        # å»ºç«‹çŸ©é™£
        if sharpe_data:
            self.sharpe_matrix = pd.DataFrame(sharpe_data).sort_index()
        
        if slope_data:
            self.slope_matrix = pd.DataFrame(slope_data).sort_index()
    
    # ===== æŸ¥è©¢æ–¹æ³• =====
    
    def get_stock_info(self, ticker: str) -> dict:
        """å–å¾—è‚¡ç¥¨è³‡è¨Š"""
        return self.stock_info.get(ticker, {})
    
    def get_all_tickers(self) -> list:
        """å–å¾—æ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼"""
        return list(self.raw_data.keys())
    
    def get_tickers_by_country(self, country: str) -> list:
        """ä¾åœ‹å®¶ç¯©é¸è‚¡ç¥¨"""
        return [
            ticker for ticker, info in self.stock_info.items()
            if info.get('country') == country and ticker in self.raw_data
        ]
    
    def get_tickers_by_industry(self, industry: str) -> list:
        """ä¾ç”¢æ¥­ç¯©é¸è‚¡ç¥¨"""
        return [
            ticker for ticker, info in self.stock_info.items()
            if info.get('industry') == industry and ticker in self.raw_data
        ]
    
    def get_industries(self) -> list:
        """å–å¾—æ‰€æœ‰ç”¢æ¥­åç¨±"""
        return list(self.watchlist.keys())
    
    def get_stock_price(self, ticker: str, date: str) -> dict:
        """
        å–å¾—è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„åƒ¹æ ¼è³‡è¨Š
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            date: æ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            {
                'ticker': 'AAPL',
                'date': '2026-02-04',
                'open': 100.0,
                'high': 105.0,
                'low': 98.0,
                'close': 103.0,
                'country': 'US'
            }
        """
        if ticker not in self.raw_data:
            return {'error': f'è‚¡ç¥¨ {ticker} ä¸å­˜åœ¨'}
        
        df = self.raw_data[ticker]
        
        # å˜—è©¦æ‰¾åˆ°æŒ‡å®šæ—¥æœŸ
        try:
            # å°‡æ—¥æœŸè½‰æ›ç‚ºå¯æ¯”è¼ƒæ ¼å¼
            target_date = pd.to_datetime(date).strftime('%Y-%m-%d')
            
            # å°‹æ‰¾æ—¥æœŸ
            matched = df[df.index.astype(str).str[:10] == target_date]
            
            if matched.empty:
                return {'error': f'æ‰¾ä¸åˆ° {ticker} åœ¨ {date} çš„è³‡æ–™'}
            
            row = matched.iloc[0]
            info = self.stock_info.get(ticker, {})
            
            return {
                'ticker': ticker,
                'date': target_date,
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'country': info.get('country', ''),
                'industry': info.get('industry', '')
            }
        except Exception as e:
            return {'error': str(e)}
    
    def get_stock_ohlcv(self, ticker: str) -> pd.DataFrame:
        """
        å–å¾—è‚¡ç¥¨çš„å®Œæ•´ OHLCV è³‡æ–™
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            DataFrame with OHLCV columns, or None if not found
        """
        if ticker not in self.raw_data:
            return None
        
        df = self.raw_data[ticker].copy()
        # ç¢ºä¿ index æ˜¯å­—ä¸²æ ¼å¼çš„æ—¥æœŸ
        df.index = df.index.astype(str).str[:10]
        return df


# ===== å–®ä¾‹æ¨¡å¼ =====

_stock_cache = None


def get_stock_cache() -> StockDataCache:
    """å–å¾—è‚¡ç¥¨è³‡æ–™å¿«å–ï¼ˆå–®ä¾‹ï¼‰"""
    global _stock_cache
    if _stock_cache is None:
        _stock_cache = StockDataCache(auto_load=True)
    return _stock_cache


def refresh_stock_cache() -> StockDataCache:
    """å¼·åˆ¶é‡æ–°æŠ“å–è‚¡ç¥¨è³‡æ–™"""
    global _stock_cache
    _stock_cache = StockDataCache(auto_load=False)
    _stock_cache.load_or_fetch(force_refresh=True)
    return _stock_cache


# ===== åˆ†æå‡½æ•¸ =====

def get_industry_top_analysis(cache: StockDataCache, country: str = None, top_n: int = 15, date: str = None) -> dict:
    """åˆ†æ Sharpe Top N çš„ç”¢æ¥­åˆ†å¸ƒ"""
    return _get_top_analysis(cache, cache.sharpe_matrix, country, top_n, 'sharpe', date)


def get_slope_top_analysis(cache: StockDataCache, country: str = None, top_n: int = 15, date: str = None) -> dict:
    """
    åˆ†æ Sharpe Slope Top N çš„ç”¢æ¥­åˆ†å¸ƒ
    
    é™åˆ¶æ¢ä»¶ï¼šåªçµ±è¨ˆ Sharpe Top 15 ç”¢æ¥­å…§çš„è‚¡ç¥¨
    1. å…ˆæ‰¾å‡º Sharpe Top 15 çš„ç”¢æ¥­
    2. ç¯©é¸å±¬æ–¼é€™äº›ç”¢æ¥­çš„æ‰€æœ‰è‚¡ç¥¨
    3. è¨ˆç®—é€™äº›è‚¡ç¥¨çš„ Slope æ’å
    """
    return _get_slope_analysis_with_sharpe_filter(cache, country, top_n, date)


def _get_slope_analysis_with_sharpe_filter(cache: StockDataCache, country: str, top_n: int, target_date: str = None) -> dict:
    """
    å¸¶æœ‰ Sharpe ç”¢æ¥­éæ¿¾çš„ Slope åˆ†æ
    """
    sharpe_matrix = cache.sharpe_matrix
    slope_matrix = cache.slope_matrix
    
    if sharpe_matrix is None or sharpe_matrix.empty or slope_matrix is None or slope_matrix.empty:
        return {'date': None, 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    us_tickers = set(cache.get_tickers_by_country('US'))
    tw_tickers = set(cache.get_tickers_by_country('TW'))
    
    # æ‰¾åˆ°ç›®æ¨™æ—¥æœŸ
    actual_date = None
    sharpe_row = None
    slope_row = None
    
    if target_date:
        target_date_str = str(target_date)[:10]
        for date in sharpe_matrix.index:
            if str(date)[:10] == target_date_str:
                actual_date = date
                sharpe_row = sharpe_matrix.loc[date]
                slope_row = slope_matrix.loc[date] if date in slope_matrix.index else None
                break
    else:
        # æ‰¾æœ€æ–°æœ‰æ•ˆæ—¥æœŸ
        for date in reversed(sharpe_matrix.index):
            sharpe_current = sharpe_matrix.loc[date]
            slope_current = slope_matrix.loc[date] if date in slope_matrix.index else None
            
            if country == 'US':
                valid_sharpe = sharpe_current[sharpe_current.index.isin(us_tickers)].dropna()
            elif country == 'TW':
                valid_sharpe = sharpe_current[sharpe_current.index.isin(tw_tickers)].dropna()
            else:
                us_valid = sharpe_current[sharpe_current.index.isin(us_tickers)].dropna()
                tw_valid = sharpe_current[sharpe_current.index.isin(tw_tickers)].dropna()
                if len(us_valid) > 0 and len(tw_valid) > 0:
                    valid_sharpe = pd.concat([us_valid, tw_valid])
                else:
                    continue
            
            if len(valid_sharpe) >= min(top_n, 5) and slope_current is not None:
                actual_date = date
                sharpe_row = sharpe_current
                slope_row = slope_current
                break
    
    if actual_date is None or sharpe_row is None or slope_row is None:
        return {'date': target_date if target_date else None, 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    # Step 1: ç¯©é¸ Sharpe è³‡æ–™
    if country == 'US':
        valid_sharpe = sharpe_row[sharpe_row.index.isin(us_tickers)].dropna()
        valid_slope = slope_row[slope_row.index.isin(us_tickers)].dropna()
    elif country == 'TW':
        valid_sharpe = sharpe_row[sharpe_row.index.isin(tw_tickers)].dropna()
        valid_slope = slope_row[slope_row.index.isin(tw_tickers)].dropna()
    else:
        us_sharpe = sharpe_row[sharpe_row.index.isin(us_tickers)].dropna()
        tw_sharpe = sharpe_row[sharpe_row.index.isin(tw_tickers)].dropna()
        valid_sharpe = pd.concat([us_sharpe, tw_sharpe])
        
        us_slope = slope_row[slope_row.index.isin(us_tickers)].dropna()
        tw_slope = slope_row[slope_row.index.isin(tw_tickers)].dropna()
        valid_slope = pd.concat([us_slope, tw_slope])
    
    if valid_sharpe.empty or valid_slope.empty:
        return {'date': str(actual_date)[:10], 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    # Step 2: æ‰¾å‡º Sharpe Top 15 çš„ç”¢æ¥­
    sharpe_top_stocks = valid_sharpe.nlargest(top_n)
    sharpe_top_industries = set()
    
    for ticker in sharpe_top_stocks.index:
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        sharpe_top_industries.add(industry)
    
    # Step 3: ç¯©é¸å±¬æ–¼é€™äº›ç”¢æ¥­çš„æ‰€æœ‰è‚¡ç¥¨ï¼ˆä¸é™æ–¼ Top 15ï¼‰
    industry_tickers = set()
    for ticker in valid_slope.index:
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        if industry in sharpe_top_industries:
            industry_tickers.add(ticker)
    
    # Step 4: å¾é€™äº›è‚¡ç¥¨ä¸­å– Slope Top N
    filtered_slope = valid_slope[valid_slope.index.isin(industry_tickers)]
    
    if filtered_slope.empty:
        return {
            'date': str(actual_date)[:10], 
            'industries': [], 
            'top_stocks': [],
            'sharpe_top_industries': list(sharpe_top_industries)
        }
    
    slope_top_stocks = filtered_slope.nlargest(top_n)
    
    # Step 5: å»ºç«‹çµæœ
    industry_stats = {}
    top_stock_list = []
    
    for ticker, value in slope_top_stocks.items():
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        stock_country = info.get('country', '')
        
        top_stock_list.append({
            'ticker': ticker,
            'slope': round(value, 6),
            'country': stock_country,
            'industry': industry
        })
        
        if industry not in industry_stats:
            industry_stats[industry] = {
                'total': 0, 'US': 0, 'TW': 0, 
                'stocks': [],
                'US_stocks': [],
                'TW_stocks': []
            }
        
        industry_stats[industry]['total'] += 1
        industry_stats[industry]['stocks'].append(ticker)
        
        if stock_country == 'US':
            industry_stats[industry]['US'] += 1
            industry_stats[industry]['US_stocks'].append(ticker)
        elif stock_country == 'TW':
            industry_stats[industry]['TW'] += 1
            industry_stats[industry]['TW_stocks'].append(ticker)
    
    industries = [
        {'name': name, **stats}
        for name, stats in industry_stats.items()
    ]
    industries.sort(key=lambda x: x['total'], reverse=True)
    
    return {
        'date': str(actual_date)[:10],
        'industries': industries,
        'top_stocks': top_stock_list,
        'sharpe_top_industries': list(sharpe_top_industries)  # é¡å¤–è¿”å› Sharpe Top ç”¢æ¥­åˆ—è¡¨
    }


def _get_top_analysis(cache: StockDataCache, matrix: pd.DataFrame, 
                      country: str, top_n: int, value_name: str, target_date: str = None) -> dict:
    """
    é€šç”¨çš„ Top åˆ†æé‚è¼¯
    
    Args:
        cache: è‚¡ç¥¨å¿«å–
        matrix: Sharpe æˆ– Slope çŸ©é™£
        country: ç¯©é¸åœ‹å®¶ (US/TW/None)
        top_n: å–å‰ N å
        value_name: å€¼çš„åç¨± ('sharpe' æˆ– 'slope')
        target_date: æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)ï¼ŒNone å‰‡ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    """
    if matrix is None or matrix.empty:
        return {'date': None, 'industries': [], 'top_stocks': []}
    
    us_tickers = set(cache.get_tickers_by_country('US'))
    tw_tickers = set(cache.get_tickers_by_country('TW'))
    
    # å¦‚æœæŒ‡å®šæ—¥æœŸï¼Œç›´æ¥ä½¿ç”¨è©²æ—¥æœŸ
    if target_date:
        # è½‰æ›å­—ä¸²ç‚ºå¯æ¯”å°çš„æ ¼å¼
        target_date_str = str(target_date)[:10]
        
        # åœ¨ matrix ä¸­å°‹æ‰¾è©²æ—¥æœŸ
        for date in matrix.index:
            if str(date)[:10] == target_date_str:
                current_row = matrix.loc[date]
                
                if country == 'US':
                    row = current_row[current_row.index.isin(us_tickers)].dropna()
                elif country == 'TW':
                    row = current_row[current_row.index.isin(tw_tickers)].dropna()
                else:
                    us_valid = current_row[current_row.index.isin(us_tickers)].dropna()
                    tw_valid = current_row[current_row.index.isin(tw_tickers)].dropna()
                    row = pd.concat([us_valid, tw_valid])
                
                if not row.empty:
                    return _build_analysis_result(cache, row, date, top_n, value_name)
        
        # æŒ‡å®šæ—¥æœŸæ²’æœ‰è³‡æ–™ï¼Œè¿”å›ç©ºçµæœ
        return {'date': target_date_str, 'industries': [], 'top_stocks': []}
    
    # æ²’æœ‰æŒ‡å®šæ—¥æœŸï¼Œå°‹æ‰¾æœ€æ–°æœ‰æ•ˆæ—¥æœŸ
    latest_date = None
    row = None
    
    for date in reversed(matrix.index):
        current_row = matrix.loc[date]
        
        if country == 'US':
            valid_data = current_row[current_row.index.isin(us_tickers)].dropna()
            if len(valid_data) >= min(top_n, len(us_tickers)):
                latest_date = date
                row = valid_data
                break
        elif country == 'TW':
            valid_data = current_row[current_row.index.isin(tw_tickers)].dropna()
            if len(valid_data) >= min(top_n, len(tw_tickers)):
                latest_date = date
                row = valid_data
                break
        else:
            us_valid = current_row[current_row.index.isin(us_tickers)].dropna()
            tw_valid = current_row[current_row.index.isin(tw_tickers)].dropna()
            if len(us_valid) > 0 and len(tw_valid) > 0:
                all_valid = pd.concat([us_valid, tw_valid])
                latest_date = date
                row = all_valid
                break
    
    if latest_date is None or row is None or row.empty:
        return {'date': None, 'industries': [], 'top_stocks': []}
    
    return _build_analysis_result(cache, row, latest_date, top_n, value_name)


def _build_analysis_result(cache: StockDataCache, row: pd.Series, 
                           date, top_n: int, value_name: str) -> dict:
    """å»ºç«‹åˆ†æçµæœ"""
    # å– Top N
    top_stocks = row.nlargest(top_n)
    
    # åˆ†æç”¢æ¥­åˆ†å¸ƒ
    industry_stats = {}
    top_stock_list = []
    
    for ticker, value in top_stocks.items():
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        stock_country = info.get('country', '')
        
        top_stock_list.append({
            'ticker': ticker,
            value_name: round(value, 6) if value_name == 'slope' else round(value, 3),
            'country': stock_country,
            'industry': industry
        })
        
        if industry not in industry_stats:
            industry_stats[industry] = {
                'total': 0, 'US': 0, 'TW': 0, 
                'stocks': [],        # æ‰€æœ‰è‚¡ç¥¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
                'US_stocks': [],     # ç¾è‚¡åˆ—è¡¨
                'TW_stocks': []      # å°è‚¡åˆ—è¡¨
            }
        
        industry_stats[industry]['total'] += 1
        industry_stats[industry]['stocks'].append(ticker)
        
        if stock_country == 'US':
            industry_stats[industry]['US'] += 1
            industry_stats[industry]['US_stocks'].append(ticker)
        elif stock_country == 'TW':
            industry_stats[industry]['TW'] += 1
            industry_stats[industry]['TW_stocks'].append(ticker)
    
    industries = [
        {'name': name, **stats}
        for name, stats in industry_stats.items()
    ]
    industries.sort(key=lambda x: x['total'], reverse=True)
    
    return {
        'date': str(date)[:10],
        'industries': industries,
        'top_stocks': top_stock_list
    }
