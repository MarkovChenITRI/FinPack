"""
è‚¡ç¥¨æ•¸æ“šå¿«å–æ¨¡çµ„ - ç³»çµ±æ ¸å¿ƒæ•¸æ“šä¾†æº

================================================================================
                                 æ¶æ§‹æ¦‚è¦½
================================================================================

ã€æ•¸æ“šæµã€‘
    yfinance API â†’ raw_data (OHLCV) â†’ pickle å¿«å–
                          â†“
    _align_data_with_bfill() â†’ aligned_data (æ—¥æœŸå°é½Š)
                          â†“
    _calculate_all_indicators() â†’ sharpe_matrix, slope_matrix

ã€é—œéµå±¬æ€§ã€‘
    raw_data       åŸå§‹ OHLCV (dict[ticker] â†’ DataFrame)
    aligned_data   æ—¥æœŸå°é½Šå¾Œçš„ OHLCV (dict[ticker] â†’ DataFrame)
    sharpe_matrix  Sharpe Ratio çŸ©é™£ (DataFrame: æ—¥æœŸ Ã— è‚¡ç¥¨)
    slope_matrix   æ’åè®ŠåŒ–çŸ©é™£ (DataFrame: æ—¥æœŸ Ã— è‚¡ç¥¨)

ã€å…ƒä»¶æ•¸æ“šå°æ‡‰è¡¨ã€‘âš ï¸ æ‰€æœ‰å…ƒä»¶å¿…é ˆä½¿ç”¨ç›¸åŒæ•¸æ“šä¾†æº
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ å…ƒä»¶              â”‚ æ•¸æ“šä¾†æº                            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ K ç·šåœ–            â”‚ aligned_data                        â”‚
    â”‚ Sharpe æŸ±ç‹€åœ–     â”‚ sharpe_matrix                       â”‚
    â”‚ å¢é•·ç‡æŸ±ç‹€åœ–      â”‚ slope_matrix                        â”‚
    â”‚ äº¤æ˜“æ¨¡æ“¬å™¨        â”‚ aligned_data                        â”‚
    â”‚ å›æ¸¬å¼•æ“-åƒ¹æ ¼     â”‚ aligned_data                        â”‚
    â”‚ å›æ¸¬å¼•æ“-æ’å     â”‚ sharpe_matrix / slope_matrix        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
                                 è¨­è¨ˆåŸå‰‡
================================================================================

ã€å¿«å–åŸå‰‡ã€‘
    âœ… å¿«å–ï¼šraw_data, watchlist, stock_info, last_update
    âŒ ä¸å¿«å–ï¼šsharpe_matrix, slope_matrixï¼ˆæ¯æ¬¡è¼‰å…¥é‡ç®—ï¼‰

ã€æ—¥æœŸå°é½Šã€‘
    ä¸åŒå¸‚å ´äº¤æ˜“æ—¥ä¸åŒ â†’ _align_data_with_bfill() çµ±ä¸€æ—¥æœŸ
    1. éæ¿¾æœ‰æ•ˆäº¤æ˜“æ—¥ï¼ˆâ‰¥50 æ”¯è‚¡ç¥¨æœ‰è³‡æ–™ï¼‰
    2. æ¯æ”¯è‚¡ç¥¨ reindex åˆ°çµ±ä¸€æ—¥æœŸ
    3. bfill().ffill() å¡«è£œç¼ºå¤±å€¼

ã€Inf/NaN è™•ç†ã€‘
    _calculate_sharpe(): rolling_std=0 â†’ Inf â†’ NaN
    sharpe_matrix: Inf/-Inf â†’ NaN â†’ bfill/ffill
    slope_matrix: ç¬¬ä¸€è¡Œ NaN â†’ 0
    API clean_nan(): NaN/Inf â†’ JSON null

ã€ä¿®æ”¹æ³¨æ„ã€‘
    - æ–°å¢æŒ‡æ¨™ï¼šä¿®æ”¹ _calculate_all_indicators()
    - ç¦æ­¢åœ¨ _save_to_cache() å­˜è¡ç”ŸæŒ‡æ¨™
    - ç¦æ­¢åœ¨ _fetch_stock_history() è¨ˆç®—æŒ‡æ¨™

================================================================================
                                 å…¬å¼èªªæ˜
================================================================================

ã€Sharpe Ratioã€‘
    Sharpe = (æ»¾å‹•å¹³å‡è¶…é¡å ±é…¬ / æ»¾å‹•æ¨™æº–å·®) Ã— âˆš252
    - è¶…é¡å ±é…¬ = æ—¥å ±é…¬ç‡ - æ—¥ç„¡é¢¨éšªåˆ©ç‡(4%/252)
    - æ»¾å‹•è¦–çª— = 252 å¤©
    - è§£è®€ï¼š>1 å„ªè‰¯ï¼Œ>2 å„ªç§€ï¼Œ<0 è™§æ

ã€Ranking Changeï¼ˆæ’åè®ŠåŒ–ï¼‰ã€‘
    Ranking Change = Sharpeæ’å(yesterday) - Sharpeæ’å(today)
    - +10 = æ’åä¸Šå‡ 10 ä½
    - -5 = æ’åä¸‹é™ 5 ä½
    - å‰ç«¯é¡¯ç¤ºç‚ºã€Œå¢é•·ç‡ Top 15ã€

================================================================================
"""
import pickle
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from pathlib import Path


# å¿«å–ç›®éŒ„
CACHE_DIR = Path(__file__).parent.parent / "cache"
CACHE_FILE = CACHE_DIR / "stock_data.pkl"


class StockDataCache:
    """è‚¡ç¥¨æ•¸æ“šå¿«å–å™¨"""
    
    # TradingView è¨­å®š
    WATCHLIST_ID = "118349730"
    SESSION_ID = "b379eetq1pojcel6olyymmpo1rd41nng"
    
    # è¨ˆç®—åƒæ•¸
    SHARPE_WINDOW = 252   # Sharpe è¨ˆç®—è¦–çª—
    RISK_FREE_RATE = 0.04
    
    def __init__(self, auto_load: bool = True):
        # ====================================================================
        # åŸå§‹è³‡æ–™ï¼ˆæœƒè¢«å¿«å–åˆ° pickleï¼‰
        # æ³¨æ„ï¼šåªæœ‰é€™äº›è³‡æ–™æœƒè¢«å­˜å…¥å¿«å–ï¼
        # ====================================================================
        self.raw_data = {}    # {ticker: DataFrame with OHLCV only}
        self.watchlist = {}   # {industry: {provider: [codes]}}
        self.stock_info = {}  # {ticker: {country, industry, provider}}
        self.last_update = None
        
        # ====================================================================
        # è¡ç”Ÿè³‡æ–™ï¼ˆå‹•æ…‹è¨ˆç®—ï¼Œç¦æ­¢å¿«å–ï¼ï¼‰
        # é€™äº›è³‡æ–™åœ¨æ¯æ¬¡è¼‰å…¥å¾Œç”± _calculate_all_indicators() è¨ˆç®—
        # ====================================================================
        self.aligned_data = {}      # å°é½Šæ—¥æœŸå¾Œçš„è³‡æ–™ï¼ˆç”¨ bfill å¡«è£œï¼‰
        self.unified_dates = None   # çµ±ä¸€æ—¥æœŸç´¢å¼•
        self.sharpe_matrix = None   # ç”± aligned_data è¨ˆç®—å¾—å‡º
        self.slope_matrix = None    # Sharpe æ’åè®ŠåŒ–ï¼ˆæ˜¨å¤©æ’å - ä»Šå¤©æ’åï¼‰
        self.initialized = False
        
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
        
        if auto_load:
            self.load_or_fetch()
    
    def load_or_fetch(self, force_refresh: bool = False):
        """è¼‰å…¥å¿«å–æˆ–é‡æ–°æŠ“å–è³‡æ–™"""
        if not force_refresh and self._load_from_cache():
            print(f"âœ… å¾å¿«å–è¼‰å…¥åŸå§‹è³‡æ–™ (æœ€å¾Œæ›´æ–°: {self.last_update})")
            print(f"  ğŸ“¦ raw_data: {len(self.raw_data)} æª”è‚¡ç¥¨")
        else:
            print("ğŸ“¥ é–‹å§‹æŠ“å–è‚¡ç¥¨è³‡æ–™...")
            self._fetch_all_data()
            self._save_to_cache()
            print(f"âœ… è‚¡ç¥¨è³‡æ–™æŠ“å–å®Œæˆ ({len(self.raw_data)} æª”è‚¡ç¥¨)")
        
        # çµ±ä¸€å°é½Šæ‰€æœ‰è‚¡ç¥¨çš„æ—¥æœŸï¼ˆç”¨ bfill å¡«è£œï¼‰
        print("ğŸ“… å°é½Šè‚¡ç¥¨æ—¥æœŸï¼ˆbfillï¼‰...")
        self._align_data_with_bfill()
        print(f"âœ… æ—¥æœŸå°é½Šå®Œæˆ")
        print(f"  ğŸ“… unified_dates: {len(self.unified_dates) if self.unified_dates is not None else 0} å€‹äº¤æ˜“æ—¥")
        print(f"  ğŸ“¦ aligned_data: {len(self.aligned_data)} æª”è‚¡ç¥¨")
        
        # è¼‰å…¥å¾Œè¨ˆç®—è¡ç”ŸæŒ‡æ¨™ï¼ˆåŸºæ–¼å°é½Šå¾Œçš„è³‡æ–™ï¼‰
        print("ğŸ“Š è¨ˆç®—è¡ç”ŸæŒ‡æ¨™...")
        self._calculate_all_indicators()
        self.initialized = True
        print(f"âœ… æŒ‡æ¨™è¨ˆç®—å®Œæˆ")
        print(f"  ğŸ“Š sharpe_matrix: {self.sharpe_matrix.shape if self.sharpe_matrix is not None and not self.sharpe_matrix.empty else 'None/Empty'}")
        print(f"  ğŸ“Š slope_matrix: {self.slope_matrix.shape if self.slope_matrix is not None and not self.slope_matrix.empty else 'None/Empty'}")
    
    # ===== å¿«å–ç®¡ç† =====
    
    def _load_from_cache(self) -> bool:
        """å¾å¿«å–è¼‰å…¥åŸå§‹è³‡æ–™"""
        if not CACHE_FILE.exists():
            return False
        
        try:
            with open(CACHE_FILE, 'rb') as f:
                cache = pickle.load(f)
            
            cache_time = cache.get('last_update')
            if cache_time:
                cache_age = datetime.now() - cache_time
                if cache_age > timedelta(days=1):
                    print("âš ï¸ å¿«å–å·²éæœŸï¼Œå°‡é‡æ–°æŠ“å–")
                    return False
            
            self.raw_data = cache.get('raw_data', {})
            self.watchlist = cache.get('watchlist', {})
            self.stock_info = cache.get('stock_info', {})
            self.last_update = cache.get('last_update')
            
            return len(self.raw_data) > 0
            
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥å¿«å–å¤±æ•—: {e}")
            return False
    
    def _save_to_cache(self):
        """
        å„²å­˜åŸå§‹è³‡æ–™åˆ°å¿«å–
        
        âš ï¸ é‡è¦ï¼šç¦æ­¢åœ¨æ­¤åŠ å…¥ä»»ä½•è¡ç”ŸæŒ‡æ¨™ï¼
        - âŒ ä¸è¦åŠ å…¥ sharpe_matrix
        - âŒ ä¸è¦åŠ å…¥ slope_matrix
        - âŒ ä¸è¦åŠ å…¥ä»»ä½•è¨ˆç®—å‡ºä¾†çš„è³‡æ–™
        """
        try:
            # åªå­˜åŸå§‹è³‡æ–™ï¼Œä¸å­˜è¡ç”ŸæŒ‡æ¨™
            cache = {
                'raw_data': self.raw_data,      # åªæœ‰ OHLCV
                'watchlist': self.watchlist,    # ç”¢æ¥­åˆ†é¡
                'stock_info': self.stock_info,  # è‚¡ç¥¨åŸºæœ¬è³‡è¨Š
                'last_update': self.last_update # æ›´æ–°æ™‚é–“
                # âŒ ç¦æ­¢åŠ å…¥ sharpe_matrix, slope_matrix ç­‰è¡ç”Ÿè³‡æ–™
            }
            with open(CACHE_FILE, 'wb') as f:
                pickle.dump(cache, f)
            print(f"ğŸ’¾ å·²å„²å­˜å¿«å–è‡³ {CACHE_FILE}")
        except Exception as e:
            print(f"âš ï¸ å„²å­˜å¿«å–å¤±æ•—: {e}")
    
    # ===== è³‡æ–™æŠ“å– =====
    
    def _fetch_watchlist(self) -> dict:
        """å¾ TradingView å–å¾—æŠ•è³‡çµ„åˆæ¸…å–®"""
        import requests
        
        url = f'https://in.tradingview.com/api/v1/symbols_list/custom/{self.WATCHLIST_ID}'
        headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'cookie': f'sessionid={self.SESSION_ID}',
            'x-requested-with': 'XMLHttpRequest',
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            symbols = response.json()["symbols"]
        except Exception as e:
            print(f"âš ï¸ TradingView ç„¡å›æ‡‰: {e}")
            return {}
        
        result = {}
        current_key = None
        
        for item in symbols:
            if "###" in item:
                current_key = item.strip("###\u2064")
                result[current_key] = {}
            elif current_key:
                provider, code = item.split(":", 1)
                if provider not in result[current_key]:
                    result[current_key][provider] = []
                
                # è½‰æ›ç‚º yfinance æ ¼å¼
                if provider in ['NASDAQ', 'NYSE']:
                    yf_code = code
                    country = 'US'
                elif provider == 'TWSE':
                    yf_code = f"{code}.TW"
                    country = 'TW'
                else:
                    continue
                
                result[current_key][provider].append(yf_code)
                
                self.stock_info[yf_code] = {
                    'country': country,
                    'industry': current_key,
                    'provider': provider,
                    'original_code': code
                }
        
        return result
    
    def _fetch_stock_history(self, ticker: str, period: str = "6y") -> pd.DataFrame:
        """
        ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ­·å²æ•¸æ“š
        
        âš ï¸ é‡è¦ï¼šæ­¤å‡½æ•¸åªå›å‚³åŸå§‹ OHLCV è³‡æ–™ï¼
        - âŒ ä¸è¦åœ¨é€™è£¡è¨ˆç®— Sharpe
        - âŒ ä¸è¦åœ¨é€™è£¡è¨ˆç®— Returns
        - âŒ ä¸è¦åœ¨é€™è£¡åŠ å…¥ä»»ä½•è¡ç”Ÿæ¬„ä½
        
        Returns:
            DataFrame with columns: Open, High, Low, Close, Volume (åƒ…æ­¤äº”æ¬„)
        """
        try:
            df = yf.Ticker(ticker).history(period=period, interval="1d")
            if df.empty:
                return pd.DataFrame()
            
            df = df.tz_localize(None)
            df = df.sort_index()
            # âš ï¸ åªä¿ç•™åŸå§‹æ¬„ä½ï¼Œç¦æ­¢åŠ å…¥è¡ç”Ÿæ¬„ä½ï¼
            return df[['Open', 'High', 'Low', 'Close', 'Volume']]
        except Exception as e:
            print(f"  âš ï¸ {ticker}: {e}")
            return pd.DataFrame()
    
    def _fetch_all_data(self):
        """æŠ“å–æ‰€æœ‰è‚¡ç¥¨çš„åŸå§‹è³‡æ–™ï¼ˆå«å¸‚å ´æŒ‡æ•¸ï¼‰"""
        self.watchlist = self._fetch_watchlist()
        
        if not self.watchlist:
            print("âš ï¸ ç„¡æ³•å–å¾— watchlist")
            return
        
        # å…ˆæŠ“å–å¸‚å ´æŒ‡æ•¸ï¼ˆå„ªå…ˆï¼Œç¢ºä¿ K ç·šåœ–æœ‰è³‡æ–™ï¼‰
        market_indices = [
            ('^IXIC', 'NASDAQ', 'US'),      # NASDAQ æŒ‡æ•¸
            ('^TWII', 'TWSE', 'TW'),        # å°ç£åŠ æ¬ŠæŒ‡æ•¸
            ('GC=F', 'CME', 'US'),          # é»ƒé‡‘æœŸè²¨
            ('BTC-USD', 'CRYPTO', 'US'),    # æ¯”ç‰¹å¹£
            ('TLT', 'NYSE', 'US'),          # ç¾åœ‹20å¹´æœŸå…¬å‚µ ETF
        ]
        
        # âš ï¸ é‡è¦ï¼šæ‰€æœ‰è³‡æ–™çµ±ä¸€ä½¿ç”¨ 6yï¼Œç¢ºä¿æŒ‡æ¨™è¨ˆç®—å¾Œä»æœ‰ 5 å¹´å¯ç”¨
        # ä¸è¦ä¿®æ”¹é€™å€‹å€¼ï¼å¦‚éœ€èª¿æ•´è«‹åŒæ™‚ä¿®æ”¹æª”æ¡ˆé–‹é ­çš„èªªæ˜æ–‡ä»¶
        DATA_PERIOD = "6y"
        
        print(f"ğŸ“ˆ æŠ“å–å¸‚å ´æŒ‡æ•¸ï¼ˆ{DATA_PERIOD}ï¼‰...")
        for ticker, provider, country in market_indices:
            print(f"  æŠ“å– {ticker}...", end=" ")
            df = self._fetch_stock_history(ticker, period=DATA_PERIOD)
            
            if df.empty:
                print("âŒ ç„¡è³‡æ–™")
                continue
            
            self.raw_data[ticker] = df
            self.stock_info[ticker] = {
                'country': country,
                'industry': 'Market Index',
                'provider': provider,
                'original_code': ticker
            }
            print(f"âœ… {len(df)} ç­†")
        
        all_tickers = list(self.stock_info.keys())
        # éæ¿¾æ‰å·²ç¶“æŠ“å–çš„å¸‚å ´æŒ‡æ•¸
        stock_tickers = [t for t in all_tickers if t not in [m[0] for m in market_indices]]
        print(f"ğŸ“Š å…± {len(stock_tickers)} æª”è‚¡ç¥¨å¾…æŠ“å–")
        
        for i, ticker in enumerate(stock_tickers):
            print(f"  [{i+1}/{len(stock_tickers)}] æŠ“å– {ticker}...", end=" ")
            
            # âš ï¸ ä½¿ç”¨çµ±ä¸€çš„ DATA_PERIODï¼Œä¸è¦ç¡¬ç·¨ç¢¼ï¼
            df = self._fetch_stock_history(ticker, period=DATA_PERIOD)
            
            if df.empty:
                print("âŒ ç„¡è³‡æ–™")
                continue
            
            self.raw_data[ticker] = df
            print(f"âœ… {len(df)} ç­†")
        
        self.last_update = datetime.now()
    
    # =========================================================================
    # æ—¥æœŸå°é½Š
    # =========================================================================
    
    def _align_data_with_bfill(self):
        """
        å°é½Šæ‰€æœ‰è‚¡ç¥¨çš„æ—¥æœŸï¼Œä¸¦ç”¨ bfill å¡«è£œç©ºç¼º
        
        ä¸åŒå¸‚å ´æœ‰ä¸åŒçš„äº¤æ˜“æ—¥ï¼ˆå¦‚é€±æœ«åªæœ‰ BTC-USD æœ‰è³‡æ–™ï¼‰ï¼Œ
        é€™æœƒå°è‡´è¨ˆç®— slope/ranking æ™‚å‡ºç¾å¤§é‡ NaNã€‚
        
        è§£æ±ºæ–¹æ¡ˆï¼š
        1. å»ºç«‹çµ±ä¸€æ—¥æœŸç´¢å¼•ï¼ˆæ‰€æœ‰è‚¡ç¥¨æ—¥æœŸçš„è¯é›†ï¼‰
        2. éæ¿¾å‡ºã€Œæœ‰æ•ˆäº¤æ˜“æ—¥ã€ï¼ˆâ‰¥50 æ”¯è‚¡ç¥¨æœ‰è³‡æ–™çš„æ—¥å­ï¼‰
        3. æ¯æ”¯è‚¡ç¥¨ reindex åˆ°çµ±ä¸€æ—¥æœŸ
        4. ä½¿ç”¨ bfill (backward fill) å¡«è£œç¼ºå¤±å€¼
        
        é€™ç¢ºä¿æ‰€æœ‰æŒ‡æ¨™è¨ˆç®—éƒ½åŸºæ–¼ç›¸åŒçš„æ—¥æœŸåŸºæº–ã€‚
        """
        if not self.raw_data:
            self.aligned_data = {}
            self.unified_dates = pd.DatetimeIndex([])
            return
        
        # Step 1: æ”¶é›†æ‰€æœ‰æ—¥æœŸï¼Œä¸¦çµ±è¨ˆæ¯å€‹æ—¥æœŸæœ‰å¤šå°‘è‚¡ç¥¨æœ‰è³‡æ–™
        date_stock_count = {}
        for ticker, df in self.raw_data.items():
            if df.empty:
                continue
            for date in df.index:
                date_stock_count[date] = date_stock_count.get(date, 0) + 1
        
        # Step 2: éæ¿¾å‡ºæœ‰æ•ˆäº¤æ˜“æ—¥ï¼ˆâ‰¥50 æ”¯è‚¡ç¥¨æœ‰è³‡æ–™ï¼‰
        # é€™æœƒæ’é™¤é€±æœ«ï¼ˆåªæœ‰åŠ å¯†è²¨å¹£äº¤æ˜“ï¼‰å’Œå…¶ä»–éä¸»è¦äº¤æ˜“æ—¥
        MIN_STOCKS_FOR_VALID_DAY = 50
        valid_dates = [
            date for date, count in date_stock_count.items()
            if count >= MIN_STOCKS_FOR_VALID_DAY
        ]
        
        if not valid_dates:
            # å¦‚æœæ²’æœ‰æœ‰æ•ˆæ—¥æœŸï¼ˆè‚¡ç¥¨å¤ªå°‘ï¼‰ï¼Œä½¿ç”¨æ‰€æœ‰æ—¥æœŸ
            valid_dates = list(date_stock_count.keys())
        
        self.unified_dates = pd.DatetimeIndex(sorted(valid_dates))
        
        # Step 3: å°é½Šæ¯æ”¯è‚¡ç¥¨çš„è³‡æ–™
        self.aligned_data = {}
        for ticker, df in self.raw_data.items():
            if df.empty:
                continue
            
            # Reindex åˆ°çµ±ä¸€æ—¥æœŸï¼Œç„¶å¾Œ bfill
            # bfill: ç”¨ã€Œä¸‹ä¸€å€‹æœ‰æ•ˆå€¼ã€å¡«è£œç©ºç¼º
            # é€™å°è‚¡ç¥¨åˆç†ï¼šå‡æ—¥ç”¨å‰ä¸€å€‹äº¤æ˜“æ—¥çš„æ”¶ç›¤åƒ¹
            aligned_df = df.reindex(self.unified_dates).bfill()
            
            # å°æ–¼é–‹é ­çš„ NaNï¼ˆæ²’æœ‰å¾ŒçºŒå€¼å¯ bfillï¼‰ï¼Œç”¨ ffill è£œ
            aligned_df = aligned_df.ffill()
            
            self.aligned_data[ticker] = aligned_df
        
        # è¨˜éŒ„éæ¿¾æ‰çš„æ—¥æœŸæ•¸é‡ï¼ˆdebug ç”¨ï¼‰
        total_dates = len(date_stock_count)
        filtered_dates = total_dates - len(self.unified_dates)
        if filtered_dates > 0:
            print(f"  ğŸ“… éæ¿¾æ‰ {filtered_dates} å€‹éä¸»è¦äº¤æ˜“æ—¥ï¼ˆå¦‚é€±æœ«ï¼‰")

    # =========================================================================
    # è¡ç”ŸæŒ‡æ¨™è¨ˆç®—å€
    # =========================================================================
    # æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™çš„è¨ˆç®—é‚è¼¯éƒ½æ”¾åœ¨é€™è£¡
    # æ–°å¢æŒ‡æ¨™æ™‚ï¼š
    #   1. æ–°å¢è¨ˆç®—å‡½æ•¸ï¼ˆå¦‚ _calculate_xxxï¼‰
    #   2. åœ¨ _calculate_all_indicators() ä¸­èª¿ç”¨
    #   3. åœ¨ class ä¸­æ–°å¢å°æ‡‰çš„ matrix å±¬æ€§ï¼ˆè¨­ç‚º Noneï¼‰
    # =========================================================================
    
    def _calculate_sharpe(self, close_series: pd.Series) -> pd.Series:
        """è¨ˆç®—æ»¾å‹• Sharpe æ¯”ç‡"""
        if close_series.empty:
            return pd.Series(dtype=float)
        
        returns = close_series.pct_change()
        daily_rf = self.RISK_FREE_RATE / self.SHARPE_WINDOW
        excess_returns = returns - daily_rf
        
        rolling_mean = excess_returns.rolling(self.SHARPE_WINDOW).mean()
        rolling_std = excess_returns.rolling(self.SHARPE_WINDOW).std()
        
        # é¿å…é™¤ä»¥é›¶ç”¢ç”Ÿ Inf
        rolling_std = rolling_std.replace(0, np.nan)
        
        sharpe = rolling_mean / rolling_std * np.sqrt(self.SHARPE_WINDOW)
        
        # å°‡ Inf/-Inf æ›¿æ›ç‚º NaNï¼Œç„¶å¾Œç”¨ bfill å¡«è£œ
        sharpe = sharpe.replace([np.inf, -np.inf], np.nan)
        sharpe = sharpe.bfill().ffill()
        
        return sharpe
    
    def _calculate_ranking_change(self, sharpe_matrix: pd.DataFrame) -> pd.DataFrame:
        """
        è¨ˆç®— Sharpe æ’åè®ŠåŒ–ï¼ˆå‰ä¸€äº¤æ˜“æ—¥æ’å - ä»Šå¤©æ’åï¼‰
        
        æ­£å€¼è¡¨ç¤ºæ’åä¸Šå‡ï¼ˆä¾‹ï¼šå¾ #20 å‡åˆ° #10 = +10ï¼‰
        è² å€¼è¡¨ç¤ºæ’åä¸‹é™
        
        ç”¨æ–¼å‰ç«¯ã€Œå¢é•·ç‡ Top 15ã€é¡¯ç¤ºï¼Œæ‰¾å‡ºæ’åå¿«é€Ÿä¸Šå‡çš„è‚¡ç¥¨
        é€™æ¯”å–®æ—¥æ•¸å€¼è®ŠåŒ–æ›´æœ‰æ„ç¾©ï¼Œèƒ½çœŸæ­£åæ˜ ã€Œèª°åœ¨å´›èµ·ã€
        
        æ³¨æ„ï¼šå› ç‚º aligned_data å·²ç¶“éæ¿¾æ‰é€±æœ«ç­‰éä¸»è¦äº¤æ˜“æ—¥ï¼Œ
        é€™è£¡ç›´æ¥ shift(1) å°±æ˜¯æ­£ç¢ºçš„å‰ä¸€äº¤æ˜“æ—¥ã€‚
        """
        if sharpe_matrix.empty:
            return pd.DataFrame()
        
        # è¨ˆç®—æ¯æ—¥æ’åï¼ˆ1 = æœ€é«˜ Sharpeï¼Œæ•¸å­—è¶Šå°è¶Šå¥½ï¼‰
        # ascending=False: Sharpe è¶Šé«˜æ’åè¶Šå‰
        # method='min': ç›¸åŒå€¼çµ¦ç›¸åŒæ’å
        ranking_matrix = sharpe_matrix.rank(axis=1, ascending=False, method='min')
        
        # è¨ˆç®—æ’åè®ŠåŒ–ï¼šå‰ä¸€äº¤æ˜“æ—¥æ’å - ä»Šå¤©æ’å
        # æ­£å€¼ = æ’åä¸Šå‡ï¼ˆå¾ 20 å‡åˆ° 10 = 20-10 = +10ï¼‰
        # è² å€¼ = æ’åä¸‹é™ï¼ˆå¾ 10 é™åˆ° 20 = 10-20 = -10ï¼‰
        ranking_change = ranking_matrix.shift(1) - ranking_matrix
        
        return ranking_change
    
    def _calculate_all_indicators(self):
        """
        è¨ˆç®—æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™ï¼ˆæ¯æ¬¡è¼‰å…¥å¿«å–å¾ŒåŸ·è¡Œï¼‰
        
        é€™æ˜¯è¡ç”ŸæŒ‡æ¨™çš„å”¯ä¸€è¨ˆç®—å…¥å£é»ï¼
        æ–°å¢æŒ‡æ¨™æ™‚ï¼Œåœ¨é€™è£¡æ·»åŠ è¨ˆç®—é‚è¼¯ã€‚
        
        é‡è¦ï¼šä½¿ç”¨ aligned_dataï¼ˆå°é½Šå¾Œçš„è³‡æ–™ï¼‰è¨ˆç®—ï¼Œç¢ºä¿æ‰€æœ‰æ—¥æœŸä¸€è‡´ã€‚
        
        ç›®å‰è¨ˆç®—çš„æŒ‡æ¨™ï¼š
        - sharpe_matrix: æ»¾å‹• Sharpe Ratioï¼ˆ252å¤©è¦–çª—ï¼‰
        - slope_matrix: Sharpe æ’åè®ŠåŒ–ï¼ˆæ˜¨å¤©æ’å - ä»Šå¤©æ’åï¼‰ï¼Œæ‰¾å‡ºæ’åå¿«é€Ÿä¸Šå‡çš„è‚¡ç¥¨
                        æ­£å€¼ = æ’åä¸Šå‡ï¼ˆä¾‹ï¼š+10 è¡¨ç¤ºå¾ç¬¬ 20 åå‡åˆ°ç¬¬ 10 åï¼‰
                        è² å€¼ = æ’åä¸‹é™
        """
        sharpe_data = {}
        
        print(f"  ğŸ“Š aligned_data æœ‰ {len(self.aligned_data)} æª”è‚¡ç¥¨")
        
        # ä½¿ç”¨å°é½Šå¾Œçš„è³‡æ–™è¨ˆç®—ï¼ˆç¢ºä¿æ‰€æœ‰è‚¡ç¥¨æ—¥æœŸä¸€è‡´ï¼‰
        for ticker, df in self.aligned_data.items():
            if 'Close' not in df.columns:
                print(f"    âš ï¸ {ticker} æ²’æœ‰ Close æ¬„ä½ï¼Œè·³é")
                continue
            
            # è¨ˆç®— Sharpe
            sharpe = self._calculate_sharpe(df['Close'])
            sharpe_data[ticker] = sharpe
        
        # å»ºç«‹ Sharpe çŸ©é™£
        if sharpe_data:
            self.sharpe_matrix = pd.DataFrame(sharpe_data).sort_index()
            
            # å°‡ä»»ä½•å‰©é¤˜çš„ Inf æ›¿æ›ç‚º NaNï¼Œç„¶å¾Œç”¨ bfill/ffill å¡«è£œ
            self.sharpe_matrix = self.sharpe_matrix.replace([np.inf, -np.inf], np.nan)
            self.sharpe_matrix = self.sharpe_matrix.bfill().ffill()
            
            # è¨ˆç®—æ’åè®ŠåŒ–ï¼ˆåŸºæ–¼å®Œæ•´çš„ sharpe_matrixï¼‰
            # å› ç‚ºæ—¥æœŸå·²ç¶“å°é½Šï¼Œä¸æœƒæœ‰é€±æœ«ç­‰éä¸»è¦äº¤æ˜“æ—¥çš„å•é¡Œ
            self.slope_matrix = self._calculate_ranking_change(self.sharpe_matrix)
            
            # slope_matrix ç¬¬ä¸€è¡Œæœƒæ˜¯ NaNï¼ˆæ²’æœ‰å‰ä¸€å¤©ï¼‰ï¼Œç”¨ 0 å¡«è£œ
            self.slope_matrix = self.slope_matrix.fillna(0)
        else:
            self.sharpe_matrix = pd.DataFrame()
            self.slope_matrix = pd.DataFrame()
    
    # ===== æŸ¥è©¢æ–¹æ³• =====
    # æ³¨æ„ï¼šæ‰€æœ‰æŸ¥è©¢æ–¹æ³•éƒ½ä½¿ç”¨ aligned_dataï¼ˆå°é½Šå¾Œçš„è³‡æ–™ï¼‰
    
    def get_stock_info(self, ticker: str) -> dict:
        """å–å¾—è‚¡ç¥¨è³‡è¨Š"""
        return self.stock_info.get(ticker, {})
    
    def get_all_tickers(self) -> list:
        """å–å¾—æ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼"""
        return list(self.aligned_data.keys())
    
    def get_tickers_by_country(self, country: str) -> list:
        """ä¾åœ‹å®¶ç¯©é¸è‚¡ç¥¨"""
        return [
            ticker for ticker, info in self.stock_info.items()
            if info.get('country') == country and ticker in self.aligned_data
        ]
    
    def get_tickers_by_industry(self, industry: str) -> list:
        """ä¾ç”¢æ¥­ç¯©é¸è‚¡ç¥¨"""
        return [
            ticker for ticker, info in self.stock_info.items()
            if info.get('industry') == industry and ticker in self.aligned_data
        ]
    
    def get_industries(self) -> list:
        """å–å¾—æ‰€æœ‰ç”¢æ¥­åç¨±"""
        return list(self.watchlist.keys())
    
    def get_stock_sharpe(self, ticker: str) -> pd.Series:
        """
        å–å¾—å–®ä¸€è‚¡ç¥¨çš„ Sharpe æ™‚é–“åºåˆ—
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            Series with date index and sharpe values
        """
        if self.sharpe_matrix is None or ticker not in self.sharpe_matrix.columns:
            return pd.Series(dtype=float)
        
        return self.sharpe_matrix[ticker]
    
    def get_sharpe_matrix(self, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        å–å¾— Sharpe çŸ©é™£ï¼ˆå¯é¸æ—¥æœŸç¯„åœï¼‰
        
        Args:
            start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame with date index and ticker columns
        """
        if self.sharpe_matrix is None:
            return pd.DataFrame()
        
        df = self.sharpe_matrix.copy()
        
        if start_date:
            df = df[df.index >= start_date]
        if end_date:
            df = df[df.index <= end_date]
        
        return df
    
    def get_daily_sharpe_summary(self, date: str = None) -> dict:
        """
        å–å¾—ç‰¹å®šæ—¥æœŸçš„ Sharpe æ‘˜è¦ï¼ˆæŒ‰åœ‹å®¶åˆ†çµ„ï¼‰
        
        Args:
            date: æ—¥æœŸ (YYYY-MM-DD)ï¼ŒNone å‰‡ä½¿ç”¨æœ€æ–°æ—¥æœŸ
            
        Returns:
            {
                'date': '2026-02-05',
                'US': {'count': 30, 'mean': 1.2, 'max': 2.5, 'top3': [...]},
                'TW': {'count': 20, 'mean': 0.8, 'max': 1.8, 'top3': [...]}
            }
        """
        if self.sharpe_matrix is None or self.sharpe_matrix.empty:
            return {'date': None, 'US': {}, 'TW': {}}
        
        # æ‰¾åˆ°ç›®æ¨™æ—¥æœŸçš„è³‡æ–™
        if date:
            target_str = str(date)[:10]
            matched_dates = [d for d in self.sharpe_matrix.index if str(d)[:10] == target_str]
            if not matched_dates:
                return {'date': date, 'US': {}, 'TW': {}}
            actual_date = matched_dates[0]
        else:
            actual_date = self.sharpe_matrix.index[-1]
        
        row = self.sharpe_matrix.loc[actual_date]
        
        us_tickers = set(self.get_tickers_by_country('US'))
        tw_tickers = set(self.get_tickers_by_country('TW'))
        
        def summarize(tickers_set):
            values = row[row.index.isin(tickers_set)].dropna()
            if values.empty:
                return {'count': 0, 'mean': 0, 'max': 0, 'top3': []}
            
            top3 = values.nlargest(3)
            return {
                'count': len(values),
                'mean': round(values.mean(), 3),
                'max': round(values.max(), 3),
                'top3': [
                    {'ticker': t, 'sharpe': round(v, 3)}
                    for t, v in top3.items()
                ]
            }
        
        return {
            'date': str(actual_date)[:10],
            'US': summarize(us_tickers),
            'TW': summarize(tw_tickers)
        }

    def get_stock_price(self, ticker: str, date: str) -> dict:
        """
        å–å¾—è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„åƒ¹æ ¼è³‡è¨Š
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            date: æ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            {
                'ticker': 'AAPL',
                'date': '2026-02-04',
                'open': 100.0,
                'high': 105.0,
                'low': 98.0,
                'close': 103.0,
                'country': 'US'
            }
        """
        if ticker not in self.aligned_data:
            return {'error': f'è‚¡ç¥¨ {ticker} ä¸å­˜åœ¨'}
        
        df = self.aligned_data[ticker]
        
        # å˜—è©¦æ‰¾åˆ°æŒ‡å®šæ—¥æœŸ
        try:
            # å°‡æ—¥æœŸè½‰æ›ç‚ºå¯æ¯”è¼ƒæ ¼å¼
            target_date = pd.to_datetime(date).strftime('%Y-%m-%d')
            
            # å°‹æ‰¾æ—¥æœŸ
            matched = df[df.index.astype(str).str[:10] == target_date]
            
            if matched.empty:
                return {'error': f'æ‰¾ä¸åˆ° {ticker} åœ¨ {date} çš„è³‡æ–™'}
            
            row = matched.iloc[0]
            info = self.stock_info.get(ticker, {})
            
            return {
                'ticker': ticker,
                'date': target_date,
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'country': info.get('country', ''),
                'industry': info.get('industry', '')
            }
        except Exception as e:
            return {'error': str(e)}
    
    def get_stock_ohlcv(self, ticker: str) -> pd.DataFrame:
        """
        å–å¾—è‚¡ç¥¨çš„å®Œæ•´ OHLCV è³‡æ–™ï¼ˆä½¿ç”¨å°é½Šå¾Œçš„è³‡æ–™ï¼‰
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            DataFrame with OHLCV columns, or None if not found
        """
        if ticker not in self.aligned_data:
            return None
        
        df = self.aligned_data[ticker].copy()
        # ç¢ºä¿ index æ˜¯å­—ä¸²æ ¼å¼çš„æ—¥æœŸ
        df.index = df.index.astype(str).str[:10]
        return df


# ===== å–®ä¾‹æ¨¡å¼ =====

_stock_cache = None


def get_stock_cache() -> StockDataCache:
    """å–å¾—è‚¡ç¥¨è³‡æ–™å¿«å–ï¼ˆå–®ä¾‹ï¼‰"""
    global _stock_cache
    if _stock_cache is None:
        _stock_cache = StockDataCache(auto_load=True)
    return _stock_cache


def refresh_stock_cache() -> StockDataCache:
    """å¼·åˆ¶é‡æ–°æŠ“å–è‚¡ç¥¨è³‡æ–™"""
    global _stock_cache
    _stock_cache = StockDataCache(auto_load=False)
    _stock_cache.load_or_fetch(force_refresh=True)
    return _stock_cache


# ===== åˆ†æå‡½æ•¸ =====

def get_industry_top_analysis(cache: StockDataCache, country: str = None, top_n: int = 15, date: str = None) -> dict:
    """åˆ†æ Sharpe Top N çš„ç”¢æ¥­åˆ†å¸ƒ"""
    return _get_top_analysis(cache, cache.sharpe_matrix, country, top_n, 'sharpe', date)


def get_slope_top_analysis(cache: StockDataCache, country: str = None, top_n: int = 15, date: str = None) -> dict:
    """
    åˆ†æ Sharpe Slope Top N çš„ç”¢æ¥­åˆ†å¸ƒ
    
    é™åˆ¶æ¢ä»¶ï¼šåªçµ±è¨ˆ Sharpe Top 15 ç”¢æ¥­å…§çš„è‚¡ç¥¨
    1. å…ˆæ‰¾å‡º Sharpe Top 15 çš„ç”¢æ¥­
    2. ç¯©é¸å±¬æ–¼é€™äº›ç”¢æ¥­çš„æ‰€æœ‰è‚¡ç¥¨
    3. è¨ˆç®—é€™äº›è‚¡ç¥¨çš„ Slope æ’å
    """
    return _get_slope_analysis_with_sharpe_filter(cache, country, top_n, date)


def _get_slope_analysis_with_sharpe_filter(cache: StockDataCache, country: str, top_n: int, target_date: str = None) -> dict:
    """
    å¸¶æœ‰ Sharpe ç”¢æ¥­éæ¿¾çš„ Slope åˆ†æ
    """
    sharpe_matrix = cache.sharpe_matrix
    slope_matrix = cache.slope_matrix
    
    if sharpe_matrix is None or sharpe_matrix.empty or slope_matrix is None or slope_matrix.empty:
        return {'date': None, 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    us_tickers = set(cache.get_tickers_by_country('US'))
    tw_tickers = set(cache.get_tickers_by_country('TW'))
    
    # æ‰¾åˆ°ç›®æ¨™æ—¥æœŸ
    actual_date = None
    sharpe_row = None
    slope_row = None
    
    if target_date:
        target_date_str = str(target_date)[:10]
        for date in sharpe_matrix.index:
            if str(date)[:10] == target_date_str:
                actual_date = date
                sharpe_row = sharpe_matrix.loc[date]
                slope_row = slope_matrix.loc[date] if date in slope_matrix.index else None
                break
    else:
        # æ‰¾æœ€æ–°æœ‰æ•ˆæ—¥æœŸ
        for date in reversed(sharpe_matrix.index):
            sharpe_current = sharpe_matrix.loc[date]
            slope_current = slope_matrix.loc[date] if date in slope_matrix.index else None
            
            if country == 'US':
                valid_sharpe = sharpe_current[sharpe_current.index.isin(us_tickers)].dropna()
            elif country == 'TW':
                valid_sharpe = sharpe_current[sharpe_current.index.isin(tw_tickers)].dropna()
            else:
                us_valid = sharpe_current[sharpe_current.index.isin(us_tickers)].dropna()
                tw_valid = sharpe_current[sharpe_current.index.isin(tw_tickers)].dropna()
                if len(us_valid) > 0 and len(tw_valid) > 0:
                    valid_sharpe = pd.concat([us_valid, tw_valid])
                else:
                    continue
            
            if len(valid_sharpe) >= min(top_n, 5) and slope_current is not None:
                actual_date = date
                sharpe_row = sharpe_current
                slope_row = slope_current
                break
    
    if actual_date is None or sharpe_row is None or slope_row is None:
        return {'date': target_date if target_date else None, 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    # Step 1: ç¯©é¸ Sharpe è³‡æ–™
    if country == 'US':
        valid_sharpe = sharpe_row[sharpe_row.index.isin(us_tickers)].dropna()
        valid_slope = slope_row[slope_row.index.isin(us_tickers)].dropna()
    elif country == 'TW':
        valid_sharpe = sharpe_row[sharpe_row.index.isin(tw_tickers)].dropna()
        valid_slope = slope_row[slope_row.index.isin(tw_tickers)].dropna()
    else:
        us_sharpe = sharpe_row[sharpe_row.index.isin(us_tickers)].dropna()
        tw_sharpe = sharpe_row[sharpe_row.index.isin(tw_tickers)].dropna()
        valid_sharpe = pd.concat([us_sharpe, tw_sharpe])
        
        us_slope = slope_row[slope_row.index.isin(us_tickers)].dropna()
        tw_slope = slope_row[slope_row.index.isin(tw_tickers)].dropna()
        valid_slope = pd.concat([us_slope, tw_slope])
    
    if valid_sharpe.empty or valid_slope.empty:
        return {'date': str(actual_date)[:10], 'industries': [], 'top_stocks': [], 'sharpe_top_industries': []}
    
    # Step 2: æ‰¾å‡º Sharpe Top 15 çš„ç”¢æ¥­
    sharpe_top_stocks = valid_sharpe.nlargest(top_n)
    sharpe_top_industries = set()
    
    for ticker in sharpe_top_stocks.index:
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        sharpe_top_industries.add(industry)
    
    # Step 3: ç¯©é¸å±¬æ–¼é€™äº›ç”¢æ¥­çš„æ‰€æœ‰è‚¡ç¥¨ï¼ˆä¸é™æ–¼ Top 15ï¼‰
    industry_tickers = set()
    for ticker in valid_slope.index:
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        if industry in sharpe_top_industries:
            industry_tickers.add(ticker)
    
    # Step 4: å¾é€™äº›è‚¡ç¥¨ä¸­å– Slope Top N
    filtered_slope = valid_slope[valid_slope.index.isin(industry_tickers)]
    
    if filtered_slope.empty:
        return {
            'date': str(actual_date)[:10], 
            'industries': [], 
            'top_stocks': [],
            'sharpe_top_industries': list(sharpe_top_industries)
        }
    
    slope_top_stocks = filtered_slope.nlargest(top_n)
    
    # Step 5: å»ºç«‹çµæœ
    industry_stats = {}
    top_stock_list = []
    
    for ticker, value in slope_top_stocks.items():
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        stock_country = info.get('country', '')
        
        top_stock_list.append({
            'ticker': ticker,
            'slope': round(value, 6),
            'country': stock_country,
            'industry': industry
        })
        
        if industry not in industry_stats:
            industry_stats[industry] = {
                'total': 0, 'US': 0, 'TW': 0, 
                'stocks': [],
                'US_stocks': [],
                'TW_stocks': []
            }
        
        industry_stats[industry]['total'] += 1
        industry_stats[industry]['stocks'].append(ticker)
        
        if stock_country == 'US':
            industry_stats[industry]['US'] += 1
            industry_stats[industry]['US_stocks'].append(ticker)
        elif stock_country == 'TW':
            industry_stats[industry]['TW'] += 1
            industry_stats[industry]['TW_stocks'].append(ticker)
    
    industries = [
        {'name': name, **stats}
        for name, stats in industry_stats.items()
    ]
    industries.sort(key=lambda x: x['total'], reverse=True)
    
    return {
        'date': str(actual_date)[:10],
        'industries': industries,
        'top_stocks': top_stock_list,
        'sharpe_top_industries': list(sharpe_top_industries)  # é¡å¤–è¿”å› Sharpe Top ç”¢æ¥­åˆ—è¡¨
    }


def _get_top_analysis(cache: StockDataCache, matrix: pd.DataFrame, 
                      country: str, top_n: int, value_name: str, target_date: str = None) -> dict:
    """
    é€šç”¨çš„ Top åˆ†æé‚è¼¯
    
    Args:
        cache: è‚¡ç¥¨å¿«å–
        matrix: Sharpe æˆ– Slope çŸ©é™£
        country: ç¯©é¸åœ‹å®¶ (US/TW/None)
        top_n: å–å‰ N å
        value_name: å€¼çš„åç¨± ('sharpe' æˆ– 'slope')
        target_date: æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)ï¼ŒNone å‰‡ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    """
    if matrix is None or matrix.empty:
        return {'date': None, 'industries': [], 'top_stocks': []}
    
    us_tickers = set(cache.get_tickers_by_country('US'))
    tw_tickers = set(cache.get_tickers_by_country('TW'))
    
    # å¦‚æœæŒ‡å®šæ—¥æœŸï¼Œç›´æ¥ä½¿ç”¨è©²æ—¥æœŸ
    if target_date:
        # è½‰æ›å­—ä¸²ç‚ºå¯æ¯”å°çš„æ ¼å¼
        target_date_str = str(target_date)[:10]
        
        # åœ¨ matrix ä¸­å°‹æ‰¾è©²æ—¥æœŸ
        for date in matrix.index:
            if str(date)[:10] == target_date_str:
                current_row = matrix.loc[date]
                
                if country == 'US':
                    row = current_row[current_row.index.isin(us_tickers)].dropna()
                elif country == 'TW':
                    row = current_row[current_row.index.isin(tw_tickers)].dropna()
                else:
                    us_valid = current_row[current_row.index.isin(us_tickers)].dropna()
                    tw_valid = current_row[current_row.index.isin(tw_tickers)].dropna()
                    row = pd.concat([us_valid, tw_valid])
                
                if not row.empty:
                    return _build_analysis_result(cache, row, date, top_n, value_name)
        
        # æŒ‡å®šæ—¥æœŸæ²’æœ‰è³‡æ–™ï¼Œè¿”å›ç©ºçµæœ
        return {'date': target_date_str, 'industries': [], 'top_stocks': []}
    
    # æ²’æœ‰æŒ‡å®šæ—¥æœŸï¼Œå°‹æ‰¾æœ€æ–°æœ‰æ•ˆæ—¥æœŸ
    latest_date = None
    row = None
    
    for date in reversed(matrix.index):
        current_row = matrix.loc[date]
        
        if country == 'US':
            valid_data = current_row[current_row.index.isin(us_tickers)].dropna()
            if len(valid_data) >= min(top_n, len(us_tickers)):
                latest_date = date
                row = valid_data
                break
        elif country == 'TW':
            valid_data = current_row[current_row.index.isin(tw_tickers)].dropna()
            if len(valid_data) >= min(top_n, len(tw_tickers)):
                latest_date = date
                row = valid_data
                break
        else:
            us_valid = current_row[current_row.index.isin(us_tickers)].dropna()
            tw_valid = current_row[current_row.index.isin(tw_tickers)].dropna()
            if len(us_valid) > 0 and len(tw_valid) > 0:
                all_valid = pd.concat([us_valid, tw_valid])
                latest_date = date
                row = all_valid
                break
    
    if latest_date is None or row is None or row.empty:
        return {'date': None, 'industries': [], 'top_stocks': []}
    
    return _build_analysis_result(cache, row, latest_date, top_n, value_name)


def _build_analysis_result(cache: StockDataCache, row: pd.Series, 
                           date, top_n: int, value_name: str) -> dict:
    """å»ºç«‹åˆ†æçµæœ"""
    # å– Top N
    top_stocks = row.nlargest(top_n)
    
    # åˆ†æç”¢æ¥­åˆ†å¸ƒ
    industry_stats = {}
    top_stock_list = []
    
    for ticker, value in top_stocks.items():
        info = cache.get_stock_info(ticker)
        industry = info.get('industry', 'æœªåˆ†é¡')
        stock_country = info.get('country', '')
        
        top_stock_list.append({
            'ticker': ticker,
            value_name: round(value, 6) if value_name == 'slope' else round(value, 3),
            'country': stock_country,
            'industry': industry
        })
        
        if industry not in industry_stats:
            industry_stats[industry] = {
                'total': 0, 'US': 0, 'TW': 0, 
                'stocks': [],        # æ‰€æœ‰è‚¡ç¥¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
                'US_stocks': [],     # ç¾è‚¡åˆ—è¡¨
                'TW_stocks': []      # å°è‚¡åˆ—è¡¨
            }
        
        industry_stats[industry]['total'] += 1
        industry_stats[industry]['stocks'].append(ticker)
        
        if stock_country == 'US':
            industry_stats[industry]['US'] += 1
            industry_stats[industry]['US_stocks'].append(ticker)
        elif stock_country == 'TW':
            industry_stats[industry]['TW'] += 1
            industry_stats[industry]['TW_stocks'].append(ticker)
    
    industries = [
        {'name': name, **stats}
        for name, stats in industry_stats.items()
    ]
    industries.sort(key=lambda x: x['total'], reverse=True)
    
    return {
        'date': str(date)[:10],
        'industries': industries,
        'top_stocks': top_stock_list
    }
