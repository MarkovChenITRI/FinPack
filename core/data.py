"""
è³‡æ–™æŠ“å–æ¨¡çµ„

è² è²¬å¾ TradingView å’Œ yfinance æŠ“å–è‚¡ç¥¨è³‡æ–™
æ”¯æ´æ™ºæ…§å¿«å–ç­–ç•¥ï¼š
- DEBUG æ¨¡å¼ï¼šä½¿ç”¨æœ¬åœ°å¿«å–
- ç”Ÿç”¢æ¨¡å¼ï¼šç›´æ¥å¾ API æ“·å–
"""
import pickle
import logging
import requests
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from typing import Optional, Tuple

from .config import (
    CACHE_DIR, STOCK_CACHE_FILE,
    TRADINGVIEW_WATCHLIST_ID, TRADINGVIEW_SESSION_ID,
    DATA_PERIOD, NON_TRADABLE_INDUSTRIES, MIN_HISTORY_DAYS,
    CACHE_MAX_STALENESS_DAYS
)

logger = logging.getLogger(__name__)


# =============================================================================
# TradingView Watchlist æ“·å–
# =============================================================================

def fetch_watchlist() -> Tuple[dict, dict]:
    """
    å¾ TradingView å–å¾—æŠ•è³‡çµ„åˆæ¸…å–®
    
    Returns:
        (watchlist, stock_info)
        watchlist: {industry: {provider: [codes]}}
        stock_info: {ticker: {country, industry, provider, original_code}}
    """
    url = f'https://in.tradingview.com/api/v1/symbols_list/custom/{TRADINGVIEW_WATCHLIST_ID}'
    headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'cookie': f'sessionid={TRADINGVIEW_SESSION_ID}',
        'x-requested-with': 'XMLHttpRequest',
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        symbols = response.json()["symbols"]
    except Exception as e:
        logger.warning(f"TradingView ç„¡å›æ‡‰: {e}")
        return {}, {}
    
    watchlist = {}
    stock_info = {}
    current_key = None
    
    for item in symbols:
        if "###" in item:
            current_key = item.strip("###\u2064")
            watchlist[current_key] = {}
        elif current_key:
            if ':' not in item:
                continue
            provider, code = item.split(":", 1)
            if provider not in watchlist[current_key]:
                watchlist[current_key][provider] = []
            
            # è½‰æ›ç‚º yfinance æ ¼å¼
            if provider in ['NASDAQ', 'NYSE', 'AMEX']:
                yf_code = code
                country = 'US'
            elif provider == 'TWSE':
                yf_code = f"{code}.TW"
                country = 'TW'
            elif provider == 'TPEX':
                yf_code = f"{code}.TWO"
                country = 'TW'
            else:
                continue
            
            watchlist[current_key][provider].append(yf_code)
            
            stock_info[yf_code] = {
                'country': country,
                'industry': current_key,
                'provider': provider,
                'original_code': code
            }
    
    return watchlist, stock_info


# =============================================================================
# è‚¡ç¥¨æ­·å²è³‡æ–™æ“·å–
# =============================================================================

def fetch_stock_history(ticker: str, period: str = DATA_PERIOD) -> pd.DataFrame:
    """
    ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ­·å²æ•¸æ“š
    
    Returns:
        DataFrame with columns: Open, High, Low, Close, Volume
    """
    try:
        df = yf.Ticker(ticker).history(period=period, interval="1d")
        if df.empty:
            return pd.DataFrame()
        
        df = df.tz_localize(None)
        df = df.sort_index()
        return df[['Open', 'High', 'Low', 'Close', 'Volume']]
    except Exception as e:
        logger.debug(f"{ticker}: {e}")
        return pd.DataFrame()


def fetch_all_stock_data(show_progress: bool = True) -> Tuple[dict, dict, dict]:
    """
    æŠ“å–æ‰€æœ‰è‚¡ç¥¨è³‡æ–™
    
    Args:
        show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦ï¼ˆCLI æ¨¡å¼ç”¨ï¼‰
    
    Returns:
        (raw_data, watchlist, stock_info)
    """
    watchlist, stock_info = fetch_watchlist()
    
    if not watchlist:
        logger.warning("ç„¡æ³•å–å¾— watchlist")
        return {}, {}, {}
    
    raw_data = {}
    all_tickers = list(stock_info.keys())
    total = len(all_tickers)
    
    if show_progress:
        print(f"ğŸ“Š å…± {total} æª”è‚¡ç¥¨å¾…æŠ“å–ï¼ˆ{DATA_PERIOD}ï¼‰")
    
    for i, ticker in enumerate(all_tickers):
        industry = stock_info[ticker].get('industry', 'Unknown')
        is_index = industry in NON_TRADABLE_INDUSTRIES
        
        if show_progress:
            prefix = "ğŸ“ˆ" if is_index else "  "
            print(f"{prefix} [{i+1}/{total}] æŠ“å– {ticker} ({industry})...", end=" ")
        
        df = fetch_stock_history(ticker)
        
        if df.empty:
            if show_progress:
                print("âŒ ç„¡è³‡æ–™")
            continue
        
        if len(df) < MIN_HISTORY_DAYS:
            if show_progress:
                print(f"âš ï¸ è³‡æ–™å¤ªå°‘ ({len(df)} ç­†)")
            continue
        
        raw_data[ticker] = df
        if show_progress:
            print(f"âœ… {len(df)} ç­†")
    
    return raw_data, watchlist, stock_info


# =============================================================================
# å¿«å–æ“ä½œ
# =============================================================================

def _get_cache_data_date(raw_data: dict) -> Optional[datetime]:
    """å–å¾—å¿«å–è³‡æ–™çš„æœ€æ–°æ—¥æœŸ"""
    if not raw_data:
        return None
    sample_ticker = next(iter(raw_data))
    sample_df = raw_data[sample_ticker]
    if sample_df.empty:
        return None
    return sample_df.index[-1].date()


def load_stock_cache_raw() -> Tuple[dict, dict, dict, Optional[datetime]]:
    """
    è®€å–å¿«å–æª”æ¡ˆï¼ˆä¸åˆ¤æ–·æ™‚æ•ˆæ€§ï¼Œç›´æ¥è¿”å›ï¼‰
    
    Returns:
        (raw_data, watchlist, stock_info, last_update)
    """
    if not STOCK_CACHE_FILE.exists():
        return {}, {}, {}, None
    
    try:
        with open(STOCK_CACHE_FILE, 'rb') as f:
            cache = pickle.load(f)
        return (
            cache.get('raw_data', {}),
            cache.get('watchlist', {}),
            cache.get('stock_info', {}),
            cache.get('last_update')
        )
    except Exception as e:
        logger.warning(f"è¼‰å…¥å¿«å–å¤±æ•—: {e}")
        return {}, {}, {}, None


def load_stock_cache(max_staleness_days: int = CACHE_MAX_STALENESS_DAYS) -> Tuple[dict, dict, dict, Optional[datetime]]:
    """
    æ™ºæ…§è¼‰å…¥å¿«å–
    
    Args:
        max_staleness_days: å…è¨±çš„æœ€å¤§éæœŸå¤©æ•¸
    
    Returns:
        (raw_data, watchlist, stock_info, last_update)
    """
    logger.info(f"Stock Cache æª”æ¡ˆ: {STOCK_CACHE_FILE}")
    
    if not STOCK_CACHE_FILE.exists():
        logger.warning("Stock å¿«å–æª”æ¡ˆä¸å­˜åœ¨")
        return {}, {}, {}, None
    
    raw_data, watchlist, stock_info, cache_time = load_stock_cache_raw()
    
    if not raw_data:
        logger.warning("å¿«å–ä¸­ç„¡è‚¡ç¥¨è³‡æ–™")
        return {}, {}, {}, None
    
    # æª¢æŸ¥å¿«å–æ™‚æ•ˆæ€§
    cache_data_date = _get_cache_data_date(raw_data)
    if cache_data_date is None:
        logger.warning("ç„¡æ³•å–å¾—å¿«å–è³‡æ–™æ—¥æœŸ")
        return {}, {}, {}, None
    
    today = datetime.now().date()
    days_diff = (today - cache_data_date).days
    
    logger.info(f"å¿«å–æœ€æ–°æ•¸æ“šæ—¥æœŸ: {cache_data_date}, å·®è·: {days_diff} å¤©")
    
    if days_diff <= max_staleness_days:
        logger.info(f"å¿«å–è³‡æ–™åœ¨ {max_staleness_days} å¤©å…§ï¼Œä½¿ç”¨å¿«å–")
        return raw_data, watchlist, stock_info, cache_time
    else:
        logger.warning(f"å¿«å–è³‡æ–™å·²éæœŸ {days_diff} å¤©")
        return {}, {}, {}, None


def save_stock_cache(raw_data: dict, watchlist: dict, stock_info: dict):
    """å„²å­˜è³‡æ–™åˆ°å¿«å–"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    
    try:
        cache = {
            'raw_data': raw_data,
            'watchlist': watchlist,
            'stock_info': stock_info,
            'last_update': datetime.now()
        }
        with open(STOCK_CACHE_FILE, 'wb') as f:
            pickle.dump(cache, f)
        logger.info(f"å·²å„²å­˜ Stock å¿«å–: {len(raw_data)} æª”è‚¡ç¥¨")
    except Exception as e:
        logger.error(f"å„²å­˜ Stock å¿«å–å¤±æ•—: {e}")


def smart_load_or_fetch(use_cache: bool = False, show_progress: bool = True) -> Tuple[dict, dict, dict, Optional[datetime]]:
    """
    æ™ºæ…§è¼‰å…¥ç­–ç•¥ï¼š
    1. è‹¥ use_cache=Trueï¼Œå¼·åˆ¶ä½¿ç”¨å¿«å–
    2. å…ˆæª¢æŸ¥å¿«å–æ˜¯å¦éæœŸ
    3. è‹¥éæœŸå‰‡å˜—è©¦æŠ“å–æ–°è³‡æ–™
    4. è‹¥æŠ“å–å¤±æ•—å‰‡ fallback ä½¿ç”¨èˆŠå¿«å–
    
    Args:
        use_cache: æ˜¯å¦å¼·åˆ¶ä½¿ç”¨å¿«å–ï¼ˆ--debug æ¨¡å¼ï¼‰
        show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦
    
    Returns:
        (raw_data, watchlist, stock_info, last_update)
    """
    # use_cache=Trueï¼šå¼·åˆ¶ä½¿ç”¨å¿«å–
    if use_cache:
        logger.info("[DEBUG] ä½¿ç”¨æœ¬åœ°å¿«å–æ¨¡å¼")
        raw_data, watchlist, stock_info, last_update = load_stock_cache_raw()
        if raw_data:
            logger.info(f"[DEBUG] è¼‰å…¥å¿«å–æˆåŠŸ: {len(raw_data)} æª”è‚¡ç¥¨")
            return raw_data, watchlist, stock_info, last_update
        else:
            logger.error("[DEBUG] å¿«å–ä¸å­˜åœ¨æˆ–ç„¡æ³•è®€å–")
            return {}, {}, {}, None
    
    # ç”Ÿç”¢æ¨¡å¼ï¼šå…ˆæª¢æŸ¥å¿«å–
    raw_data, watchlist, stock_info, last_update = load_stock_cache()
    
    if raw_data:
        return raw_data, watchlist, stock_info, last_update
    
    # å¿«å–éæœŸæˆ–ä¸å­˜åœ¨ï¼Œå˜—è©¦æŠ“å–
    logger.info("é–‹å§‹æŠ“å–è‚¡ç¥¨è³‡æ–™...")
    new_raw_data, new_watchlist, new_stock_info = fetch_all_stock_data(show_progress)
    
    if new_raw_data and len(new_raw_data) > 0:
        new_last_update = datetime.now()
        save_stock_cache(new_raw_data, new_watchlist, new_stock_info)
        logger.info(f"è‚¡ç¥¨è³‡æ–™æŠ“å–å®Œæˆ: {len(new_raw_data)} æª”")
        return new_raw_data, new_watchlist, new_stock_info, new_last_update
    else:
        # æŠ“å–å¤±æ•—ï¼Œfallback åˆ°èˆŠå¿«å–
        logger.warning("æŠ“å–å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨èˆŠå¿«å–...")
        old_raw_data, old_watchlist, old_stock_info, old_last_update = load_stock_cache_raw()
        
        if old_raw_data:
            cache_data_date = _get_cache_data_date(old_raw_data)
            logger.info(f"Fallback ä½¿ç”¨èˆŠå¿«å– (è³‡æ–™æ—¥æœŸ: {cache_data_date})")
            return old_raw_data, old_watchlist, old_stock_info, old_last_update
        else:
            logger.error("ç„¡å¯ç”¨å¿«å–ï¼Œç„¡æ³•å–å¾—è³‡æ–™")
            return {}, {}, {}, None


# =============================================================================
# å¸‚å ´éæ¿¾å·¥å…·
# =============================================================================

def filter_by_market(stock_data: dict, stock_info: dict, market: str) -> Tuple[dict, dict]:
    """
    ä¾å¸‚å ´éæ¿¾è‚¡ç¥¨è³‡æ–™
    
    Args:
        market: 'global', 'us', 'tw'
    
    Returns:
        (filtered_stock_data, filtered_stock_info)
    """
    if market == 'global':
        return stock_data, stock_info
    
    target_country = 'US' if market == 'us' else 'TW'
    filtered_symbols = {s for s, info in stock_info.items() 
                        if info.get('country') == target_country}
    
    filtered_data = {s: df for s, df in stock_data.items() if s in filtered_symbols}
    filtered_info = {s: info for s, info in stock_info.items() if s in filtered_symbols}
    
    logger.info(f"éæ¿¾å¾Œ: {len(filtered_data)} æª” {target_country} è‚¡ç¥¨")
    return filtered_data, filtered_info
